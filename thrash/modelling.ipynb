{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf702572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc27bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Loading the data\n",
    "FILE_PATH = \"data/dataset/day.csv\"\n",
    "df_ = pd.read_csv(FILE_PATH, parse_dates=['dteday'])\n",
    "df_ = df_.sort_values(by='dteday').reset_index(drop=True)\n",
    "\n",
    "# split dataset\n",
    "df_last30 = df_.tail(30)\n",
    "df = df_.iloc[:-30, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c27fb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_4/kyhrjqh97571rhyj62w1kdwr0000gn/T/ipykernel_27710/1029273460.py:72: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[lag_roll_cols] = df[lag_roll_cols].fillna(method='bfill').fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning hyperparameters...\n",
      "Best parameters: {'n_estimators': 300, 'min_samples_leaf': 1, 'max_features': 0.7, 'max_depth': 30}\n",
      "Fold 1: RMSE = 723.916\n",
      "Fold 2: RMSE = 1102.279\n",
      "Fold 3: RMSE = 1489.192\n",
      "Fold 4: RMSE = 1136.414\n",
      "Fold 5: RMSE = 1026.759\n",
      "Overall OOF RMSE = 1389.668\n",
      "Per-fold RMSEs: [ 723.916 1102.279 1489.192 1136.414 1026.759]\n",
      "Final model trained on full data.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Python 3.x\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load and sort your data\n",
    "# -----------------------------\n",
    "FILE_PATH = \"data/dataset/day.csv\"\n",
    "df_ = pd.read_csv(FILE_PATH, parse_dates=['dteday'])\n",
    "df_ = df_.sort_values(by='dteday').reset_index(drop=True)\n",
    "\n",
    "# Split dataset: last 30 days for future prediction\n",
    "df_last30 = df_.tail(30)\n",
    "df = df_.iloc[:-30, :]\n",
    "\n",
    "target_col = 'cnt'\n",
    "time_col = 'dteday'\n",
    "\n",
    "# Drop unnecessary columns\n",
    "cols_to_drop = ['casual', 'registered']\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Feature Engineering\n",
    "# -----------------------------\n",
    "def add_prophet_features(df, time_col='dteday'):\n",
    "    df['time_index'] = np.arange(len(df))\n",
    "    df['dayofyear'] = df[time_col].dt.dayofyear\n",
    "    df['hour'] = 0  # daily data, so hour = 0\n",
    "    df['dayofweek'] = df[time_col].dt.dayofweek\n",
    "    df['month'] = df[time_col].dt.month\n",
    "    df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)\n",
    "\n",
    "    # Fourier terms for seasonality\n",
    "    for k in range(1, 5):  # daily harmonics\n",
    "        df[f'daily_sin_{k}'] = np.sin(2 * np.pi * k * df['hour'] / 24)\n",
    "        df[f'daily_cos_{k}'] = np.cos(2 * np.pi * k * df['hour'] / 24)\n",
    "\n",
    "    for k in range(1, 3):  # weekly harmonics\n",
    "        df[f'weekly_sin_{k}'] = np.sin(2 * np.pi * k * df['dayofweek'] / 7)\n",
    "        df[f'weekly_cos_{k}'] = np.cos(2 * np.pi * k * df['dayofweek'] / 7)\n",
    "\n",
    "    for k in range(1, 3):  # yearly harmonics\n",
    "        df[f'yearly_sin_{k}'] = np.sin(2 * np.pi * k * df['dayofyear'] / 365)\n",
    "        df[f'yearly_cos_{k}'] = np.cos(2 * np.pi * k * df['dayofyear'] / 365)\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_lags_and_rolls(df, lags=(1, 7, 14), roll_windows=(3, 7, 14)):\n",
    "    for L in lags:\n",
    "        df[f'lag_{L}'] = df[target_col].shift(L)\n",
    "    for w in roll_windows:\n",
    "        df[f'roll_mean_{w}'] = df[target_col].shift(1).rolling(w).mean()\n",
    "        df[f'roll_std_{w}'] = df[target_col].shift(1).rolling(w).std()\n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "df = add_prophet_features(df.copy())\n",
    "df = add_lags_and_rolls(df)\n",
    "\n",
    "# Interaction features\n",
    "df['temp_x_is_weekend'] = df['temp'] * df['is_weekend']\n",
    "df['atemp_x_is_weekend'] = df['atemp'] * df['is_weekend']\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Handle NaNs for lag/rolling\n",
    "# -----------------------------\n",
    "lag_roll_cols = [col for col in df.columns if col.startswith('lag_') or col.startswith('roll_')]\n",
    "df[lag_roll_cols] = df[lag_roll_cols].fillna(method='bfill').fillna(0)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Dynamic categorical detection + One-hot encoding\n",
    "# -----------------------------\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "for col in df.columns:\n",
    "    if df[col].nunique() < 20 and df[col].dtype in ['int64', 'float64']:\n",
    "        categorical_cols.append(col)\n",
    "categorical_cols = list(set(categorical_cols))\n",
    "\n",
    "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Remove unwanted columns\n",
    "# -----------------------------\n",
    "cols_to_drop = [col for col in df.columns if col.startswith('roll_std_')]\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Prepare features\n",
    "# -----------------------------\n",
    "y = df[target_col].values\n",
    "X = df.drop(columns=[target_col, time_col]).values\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Hyperparameter tuning\n",
    "# -----------------------------\n",
    "param_grid = {\n",
    "    'n_estimators': [300, 500, 800, 1000],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', 0.7]\n",
    "}\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=tscv,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Tuning hyperparameters...\")\n",
    "search.fit(X, y)\n",
    "best_rf = search.best_estimator_\n",
    "print(\"Best parameters:\", search.best_params_)\n",
    "\n",
    "# -----------------------------\n",
    "# 8) Evaluate with TimeSeriesSplit\n",
    "# -----------------------------\n",
    "oof_preds = np.zeros(len(df))\n",
    "fold_rmses = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(tscv.split(X), 1):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "    best_rf.fit(X_train, y_train)\n",
    "    preds = best_rf.predict(X_val)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "    fold_rmses.append(rmse)\n",
    "    oof_preds[val_idx] = preds\n",
    "    print(f\"Fold {fold}: RMSE = {rmse:.3f}\")\n",
    "\n",
    "overall_rmse = np.sqrt(mean_squared_error(y, oof_preds))\n",
    "print(f\"Overall OOF RMSE = {overall_rmse:.3f}\")\n",
    "print(\"Per-fold RMSEs:\", np.round(fold_rmses, 3))\n",
    "\n",
    "# -----------------------------\n",
    "# 9) Final training on full data\n",
    "# -----------------------------\n",
    "best_rf.fit(X, y)\n",
    "print(\"Final model trained on full data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00ee8618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_24</th>\n",
       "      <th>lag_168</th>\n",
       "      <th>roll_mean_3</th>\n",
       "      <th>roll_std_3</th>\n",
       "      <th>roll_mean_6</th>\n",
       "      <th>roll_std_6</th>\n",
       "      <th>roll_mean_24</th>\n",
       "      <th>roll_std_24</th>\n",
       "      <th>roll_mean_168</th>\n",
       "      <th>roll_std_168</th>\n",
       "      <th>temp_x_is_weekend</th>\n",
       "      <th>atemp_x_is_weekend</th>\n",
       "      <th>holiday_1</th>\n",
       "      <th>weathersit_2</th>\n",
       "      <th>weathersit_3</th>\n",
       "      <th>workingday_1</th>\n",
       "      <th>season_2</th>\n",
       "      <th>season_3</th>\n",
       "      <th>season_4</th>\n",
       "      <th>sin_dow_-0.7818314824680299</th>\n",
       "      <th>sin_dow_-0.433883739117558</th>\n",
       "      <th>sin_dow_0.0</th>\n",
       "      <th>sin_dow_0.43388373911755823</th>\n",
       "      <th>sin_dow_0.7818314824680298</th>\n",
       "      <th>sin_dow_0.9749279121818236</th>\n",
       "      <th>yr_1</th>\n",
       "      <th>weekday_1</th>\n",
       "      <th>weekday_2</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>weekday_4</th>\n",
       "      <th>weekday_5</th>\n",
       "      <th>weekday_6</th>\n",
       "      <th>mnth_2</th>\n",
       "      <th>mnth_3</th>\n",
       "      <th>mnth_4</th>\n",
       "      <th>mnth_5</th>\n",
       "      <th>mnth_6</th>\n",
       "      <th>mnth_7</th>\n",
       "      <th>mnth_8</th>\n",
       "      <th>mnth_9</th>\n",
       "      <th>mnth_10</th>\n",
       "      <th>mnth_11</th>\n",
       "      <th>mnth_12</th>\n",
       "      <th>cos_dow_-0.900968867902419</th>\n",
       "      <th>cos_dow_-0.2225209339563146</th>\n",
       "      <th>cos_dow_-0.22252093395631434</th>\n",
       "      <th>cos_dow_0.6234898018587334</th>\n",
       "      <th>cos_dow_0.6234898018587336</th>\n",
       "      <th>cos_dow_1.0</th>\n",
       "      <th>is_weekend_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "      <td>985.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>1045.000000</td>\n",
       "      <td>278.883488</td>\n",
       "      <td>1317.166667</td>\n",
       "      <td>346.738759</td>\n",
       "      <td>1266.875</td>\n",
       "      <td>315.075465</td>\n",
       "      <td>2744.363095</td>\n",
       "      <td>1406.355882</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "      <td>985.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>1045.000000</td>\n",
       "      <td>278.883488</td>\n",
       "      <td>1317.166667</td>\n",
       "      <td>346.738759</td>\n",
       "      <td>1266.875</td>\n",
       "      <td>315.075465</td>\n",
       "      <td>2744.363095</td>\n",
       "      <td>1406.355882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "      <td>801.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>1045.000000</td>\n",
       "      <td>278.883488</td>\n",
       "      <td>1317.166667</td>\n",
       "      <td>346.738759</td>\n",
       "      <td>1266.875</td>\n",
       "      <td>315.075465</td>\n",
       "      <td>2744.363095</td>\n",
       "      <td>1406.355882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "      <td>1349.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>1045.000000</td>\n",
       "      <td>278.883488</td>\n",
       "      <td>1317.166667</td>\n",
       "      <td>346.738759</td>\n",
       "      <td>1266.875</td>\n",
       "      <td>315.075465</td>\n",
       "      <td>2744.363095</td>\n",
       "      <td>1406.355882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>1237.333333</td>\n",
       "      <td>392.596909</td>\n",
       "      <td>1317.166667</td>\n",
       "      <td>346.738759</td>\n",
       "      <td>1266.875</td>\n",
       "      <td>315.075465</td>\n",
       "      <td>2744.363095</td>\n",
       "      <td>1406.355882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant     dteday      temp     atemp       hum  windspeed  casual  \\\n",
       "0        1 2011-01-01  0.344167  0.363625  0.805833   0.160446     331   \n",
       "1        2 2011-01-02  0.363478  0.353739  0.696087   0.248539     131   \n",
       "2        3 2011-01-03  0.196364  0.189405  0.437273   0.248309     120   \n",
       "3        4 2011-01-04  0.200000  0.212122  0.590435   0.160296     108   \n",
       "4        5 2011-01-05  0.226957  0.229270  0.436957   0.186900      82   \n",
       "\n",
       "   registered   cnt   lag_1  lag_24  lag_168  roll_mean_3  roll_std_3  \\\n",
       "0         654   985   985.0   985.0    985.0  1045.000000  278.883488   \n",
       "1         670   801   985.0   985.0    985.0  1045.000000  278.883488   \n",
       "2        1229  1349   801.0   985.0    985.0  1045.000000  278.883488   \n",
       "3        1454  1562  1349.0   985.0    985.0  1045.000000  278.883488   \n",
       "4        1518  1600  1562.0   985.0    985.0  1237.333333  392.596909   \n",
       "\n",
       "   roll_mean_6  roll_std_6  roll_mean_24  roll_std_24  roll_mean_168  \\\n",
       "0  1317.166667  346.738759      1266.875   315.075465    2744.363095   \n",
       "1  1317.166667  346.738759      1266.875   315.075465    2744.363095   \n",
       "2  1317.166667  346.738759      1266.875   315.075465    2744.363095   \n",
       "3  1317.166667  346.738759      1266.875   315.075465    2744.363095   \n",
       "4  1317.166667  346.738759      1266.875   315.075465    2744.363095   \n",
       "\n",
       "   roll_std_168  temp_x_is_weekend  atemp_x_is_weekend  holiday_1  \\\n",
       "0   1406.355882           0.344167            0.363625      False   \n",
       "1   1406.355882           0.000000            0.000000      False   \n",
       "2   1406.355882           0.000000            0.000000      False   \n",
       "3   1406.355882           0.000000            0.000000      False   \n",
       "4   1406.355882           0.000000            0.000000      False   \n",
       "\n",
       "   weathersit_2  weathersit_3  workingday_1  season_2  season_3  season_4  \\\n",
       "0          True         False         False     False     False     False   \n",
       "1          True         False         False     False     False     False   \n",
       "2         False         False          True     False     False     False   \n",
       "3         False         False          True     False     False     False   \n",
       "4         False         False          True     False     False     False   \n",
       "\n",
       "   sin_dow_-0.7818314824680299  sin_dow_-0.433883739117558  sin_dow_0.0  \\\n",
       "0                         True                       False        False   \n",
       "1                        False                       False         True   \n",
       "2                        False                       False        False   \n",
       "3                        False                       False        False   \n",
       "4                        False                       False        False   \n",
       "\n",
       "   sin_dow_0.43388373911755823  sin_dow_0.7818314824680298  \\\n",
       "0                        False                       False   \n",
       "1                        False                       False   \n",
       "2                        False                        True   \n",
       "3                        False                       False   \n",
       "4                         True                       False   \n",
       "\n",
       "   sin_dow_0.9749279121818236   yr_1  weekday_1  weekday_2  weekday_3  \\\n",
       "0                       False  False      False      False      False   \n",
       "1                       False  False      False      False      False   \n",
       "2                       False  False       True      False      False   \n",
       "3                        True  False      False       True      False   \n",
       "4                       False  False      False      False       True   \n",
       "\n",
       "   weekday_4  weekday_5  weekday_6  mnth_2  mnth_3  mnth_4  mnth_5  mnth_6  \\\n",
       "0      False      False       True   False   False   False   False   False   \n",
       "1      False      False      False   False   False   False   False   False   \n",
       "2      False      False      False   False   False   False   False   False   \n",
       "3      False      False      False   False   False   False   False   False   \n",
       "4      False      False      False   False   False   False   False   False   \n",
       "\n",
       "   mnth_7  mnth_8  mnth_9  mnth_10  mnth_11  mnth_12  \\\n",
       "0   False   False   False    False    False    False   \n",
       "1   False   False   False    False    False    False   \n",
       "2   False   False   False    False    False    False   \n",
       "3   False   False   False    False    False    False   \n",
       "4   False   False   False    False    False    False   \n",
       "\n",
       "   cos_dow_-0.900968867902419  cos_dow_-0.2225209339563146  \\\n",
       "0                       False                        False   \n",
       "1                       False                        False   \n",
       "2                       False                        False   \n",
       "3                       False                        False   \n",
       "4                        True                        False   \n",
       "\n",
       "   cos_dow_-0.22252093395631434  cos_dow_0.6234898018587334  \\\n",
       "0                         False                        True   \n",
       "1                         False                       False   \n",
       "2                         False                       False   \n",
       "3                          True                       False   \n",
       "4                         False                       False   \n",
       "\n",
       "   cos_dow_0.6234898018587336  cos_dow_1.0  is_weekend_1  \n",
       "0                       False        False          True  \n",
       "1                       False         True         False  \n",
       "2                        True        False         False  \n",
       "3                       False        False         False  \n",
       "4                       False        False         False  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "994f273b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_4/kyhrjqh97571rhyj62w1kdwr0000gn/T/ipykernel_27710/49202086.py:67: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[lag_roll_cols] = df[lag_roll_cols].fillna(method='bfill').fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning hyperparameters...\n",
      "Best parameters: {'n_estimators': 300, 'min_samples_leaf': 1, 'max_features': 0.7, 'max_depth': 30}\n",
      "Fold 1: RMSE = 2355.023\n",
      "Fold 2: RMSE = 801.114\n",
      "Fold 3: RMSE = 942.731\n",
      "Fold 4: RMSE = 1816.474\n",
      "Fold 5: RMSE = 1012.321\n",
      "Overall OOF RMSE = 1512.496\n",
      "Per-fold RMSEs: [2355.023  801.114  942.731 1816.474 1012.321]\n",
      "Final model trained on full data.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load and sort your data\n",
    "# -----------------------------\n",
    "FILE_PATH = \"data/dataset/day.csv\"\n",
    "df_ = pd.read_csv(FILE_PATH, parse_dates=['dteday'])\n",
    "df_ = df_.sort_values(by='dteday').reset_index(drop=True)\n",
    "\n",
    "# Split dataset: last 30 days for future prediction\n",
    "df_last30 = df_.tail(30)\n",
    "df = df_.iloc[:-30, :]\n",
    "\n",
    "target_col = 'cnt'\n",
    "time_col = 'dteday'\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=['casual', 'registered'])\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Feature Engineering\n",
    "# -----------------------------\n",
    "def add_prophet_features(df, time_col='dteday'):\n",
    "    df['time_index'] = np.arange(len(df))\n",
    "    df['dayofyear'] = df[time_col].dt.dayofyear\n",
    "    df['hour'] = 0  # daily data\n",
    "    df['dayofweek'] = df[time_col].dt.dayofweek\n",
    "    df['month'] = df[time_col].dt.month\n",
    "    df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)\n",
    "\n",
    "    # Fourier terms for seasonality\n",
    "    for k in range(1, 5):\n",
    "        df[f'daily_sin_{k}'] = np.sin(2 * np.pi * k * df['hour'] / 24)\n",
    "        df[f'daily_cos_{k}'] = np.cos(2 * np.pi * k * df['hour'] / 24)\n",
    "\n",
    "    for k in range(1, 3):\n",
    "        df[f'weekly_sin_{k}'] = np.sin(2 * np.pi * k * df['dayofweek'] / 7)\n",
    "        df[f'weekly_cos_{k}'] = np.cos(2 * np.pi * k * df['dayofweek'] / 7)\n",
    "\n",
    "    for k in range(1, 3):\n",
    "        df[f'yearly_sin_{k}'] = np.sin(2 * np.pi * k * df['dayofyear'] / 365)\n",
    "        df[f'yearly_cos_{k}'] = np.cos(2 * np.pi * k * df['dayofyear'] / 365)\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_lags_and_rolls(df, lags=(1, 7, 14), roll_windows=(3, 7, 14)):\n",
    "    for L in lags:\n",
    "        df[f'lag_{L}'] = df[target_col].shift(L)\n",
    "    for w in roll_windows:\n",
    "        df[f'roll_mean_{w}'] = df[target_col].shift(1).rolling(w).mean()\n",
    "        df[f'roll_std_{w}'] = df[target_col].shift(1).rolling(w).std()\n",
    "    return df\n",
    "\n",
    "df = add_prophet_features(df.copy())\n",
    "df = add_lags_and_rolls(df)\n",
    "\n",
    "# Interaction features\n",
    "df['temp_x_is_weekend'] = df['temp'] * df['is_weekend']\n",
    "df['atemp_x_is_weekend'] = df['atemp'] * df['is_weekend']\n",
    "\n",
    "# Handle NaNs\n",
    "lag_roll_cols = [col for col in df.columns if col.startswith('lag_') or col.startswith('roll_')]\n",
    "df[lag_roll_cols] = df[lag_roll_cols].fillna(method='bfill').fillna(0)\n",
    "\n",
    "# Dynamic categorical detection + One-hot encoding\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "for col in df.columns:\n",
    "    if df[col].nunique() < 20 and df[col].dtype in ['int64', 'float64']:\n",
    "        categorical_cols.append(col)\n",
    "categorical_cols = list(set(categorical_cols))\n",
    "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Remove unwanted columns\n",
    "cols_to_drop = [col for col in df.columns if col.startswith('roll_std_')]\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "# Prepare features\n",
    "y = df[target_col].values\n",
    "X = df.drop(columns=[target_col, time_col]).values\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Hyperparameter tuning\n",
    "# -----------------------------\n",
    "param_grid = {\n",
    "    'n_estimators': [300, 500, 800, 1000],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', 0.7]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=3,  # quick internal CV for tuning\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Tuning hyperparameters...\")\n",
    "search.fit(X, y)\n",
    "best_rf = search.best_estimator_\n",
    "print(\"Best parameters:\", search.best_params_)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Expanding Window Cross-Validation\n",
    "# -----------------------------\n",
    "def expanding_window_split(n_samples, n_splits=5, min_train_size=30):\n",
    "    \"\"\"Generate expanding window train/validation indices.\"\"\"\n",
    "    split_size = (n_samples - min_train_size) // n_splits\n",
    "    for i in range(n_splits):\n",
    "        train_end = min_train_size + i * split_size\n",
    "        val_end = train_end + split_size\n",
    "        yield np.arange(train_end), np.arange(train_end, val_end)\n",
    "\n",
    "oof_preds = np.zeros(len(df))\n",
    "fold_rmses = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(expanding_window_split(len(df), n_splits=5), 1):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "    best_rf.fit(X_train, y_train)\n",
    "    preds = best_rf.predict(X_val)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "    fold_rmses.append(rmse)\n",
    "    oof_preds[val_idx] = preds\n",
    "    print(f\"Fold {fold}: RMSE = {rmse:.3f}\")\n",
    "\n",
    "overall_rmse = np.sqrt(mean_squared_error(y, oof_preds))\n",
    "print(f\"Overall OOF RMSE = {overall_rmse:.3f}\")\n",
    "print(\"Per-fold RMSEs:\", np.round(fold_rmses, 3))\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Final training on full data\n",
    "# -----------------------------\n",
    "best_rf.fit(X, y)\n",
    "print(\"Final model trained on full data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df3b21d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "FEATURE_COLS = [\n",
    "    # 'dteday',\n",
    "    'season',\n",
    "    # 'yr',\n",
    "    'mnth',\n",
    "    'holiday',\n",
    "    'weekday',\n",
    "    'workingday',\n",
    "    'weathersit',\n",
    "    'temp',\n",
    "    'atemp',\n",
    "    'hum',\n",
    "    'windspeed',\n",
    "    # 'casual',\n",
    "    # 'registered',\n",
    "    # 'bikes_cnt',\n",
    "    # 'day'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857e1882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded with 731 rows and 16 columns.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 731 entries, 0 to 730\n",
      "Data columns (total 16 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   instant     731 non-null    int64         \n",
      " 1   dteday      731 non-null    datetime64[ns]\n",
      " 2   season      731 non-null    int64         \n",
      " 3   yr          731 non-null    int64         \n",
      " 4   mnth        731 non-null    int64         \n",
      " 5   holiday     731 non-null    int64         \n",
      " 6   weekday     731 non-null    int64         \n",
      " 7   workingday  731 non-null    int64         \n",
      " 8   weathersit  731 non-null    int64         \n",
      " 9   temp        731 non-null    float64       \n",
      " 10  atemp       731 non-null    float64       \n",
      " 11  hum         731 non-null    float64       \n",
      " 12  windspeed   731 non-null    float64       \n",
      " 13  casual      731 non-null    int64         \n",
      " 14  registered  731 non-null    int64         \n",
      " 15  cnt         731 non-null    int64         \n",
      "dtypes: datetime64[ns](1), float64(4), int64(11)\n",
      "memory usage: 91.5 KB\n",
      "\n",
      " None\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 1. Loading the data\n",
    "\n",
    "df = pd.read_csv(\"data/dataset/day.csv\", parse_dates=['dteday'])\n",
    "df = df.sort_values(by='dteday').reset_index(drop=True)\n",
    "\n",
    "print(f\"Data loaded with {len(df)} rows and {len(df.columns)} columns.\")\n",
    "print(\"\\n\", df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8409c24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning hyperparameters on training data...\n",
      "Best parameters: {'n_estimators': 300, 'min_samples_leaf': 1, 'max_features': 0.7, 'max_depth': 30}\n",
      "Hold-out (last 30 days) RMSE = 1094.751\n",
      "        dteday  y_true       y_pred\n",
      "701 2012-12-02    4649  4117.143333\n",
      "702 2012-12-03    6234  5454.686667\n",
      "703 2012-12-04    6606  5704.856667\n",
      "704 2012-12-05    5729  5840.530000\n",
      "705 2012-12-06    5375  4322.830000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load and sort data\n",
    "# -----------------------------\n",
    "FILE_PATH = \"data/dataset/day.csv\"\n",
    "df_ = pd.read_csv(FILE_PATH, parse_dates=['dteday'])\n",
    "df_ = df_.sort_values(by='dteday').reset_index(drop=True)\n",
    "\n",
    "# Define target and time columns\n",
    "target_col = 'cnt'\n",
    "time_col = 'dteday'\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Split for hold-out (last 30 rows)\n",
    "# -----------------------------\n",
    "df_holdout_raw = df_.tail(30).copy()     # untouched copy for later comparison if needed\n",
    "df_train_raw   = df_.iloc[:-30, :].copy()\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Feature Engineering functions\n",
    "# -----------------------------\n",
    "def add_prophet_features(df, time_col='dteday'):\n",
    "    df['time_index'] = np.arange(len(df))\n",
    "    df['dayofyear'] = df[time_col].dt.dayofyear\n",
    "    df['hour'] = 0  # daily data\n",
    "    df['dayofweek'] = df[time_col].dt.dayofweek\n",
    "    df['month'] = df[time_col].dt.month\n",
    "    df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)\n",
    "\n",
    "    # Fourier terms for seasonality\n",
    "    for k in range(1, 5):\n",
    "        df[f'daily_sin_{k}'] = np.sin(2 * np.pi * k * df['hour'] / 24)\n",
    "        df[f'daily_cos_{k}'] = np.cos(2 * np.pi * k * df['hour'] / 24)\n",
    "    for k in range(1, 3):\n",
    "        df[f'weekly_sin_{k}'] = np.sin(2 * np.pi * k * df['dayofweek'] / 7)\n",
    "        df[f'weekly_cos_{k}'] = np.cos(2 * np.pi * k * df['dayofweek'] / 7)\n",
    "    for k in range(1, 3):\n",
    "        df[f'yearly_sin_{k}'] = np.sin(2 * np.pi * k * df['dayofyear'] / 365)\n",
    "        df[f'yearly_cos_{k}'] = np.cos(2 * np.pi * k * df['dayofyear'] / 365)\n",
    "    return df\n",
    "\n",
    "def add_lags_and_rolls(df, lags=(1, 7, 14), roll_windows=(3, 7, 14), target_col='cnt'):\n",
    "    # IMPORTANT: build lags/rolls on the FULL timeline before splitting,\n",
    "    # so the hold-out rows can use past values from train.\n",
    "    for L in lags:\n",
    "        df[f'lag_{L}'] = df[target_col].shift(L)\n",
    "    for w in roll_windows:\n",
    "        df[f'roll_mean_{w}'] = df[target_col].shift(1).rolling(w).mean()\n",
    "        df[f'roll_std_{w}'] = df[target_col].shift(1).rolling(w).std()\n",
    "    return df\n",
    "\n",
    "def add_interactions(df):\n",
    "    if 'temp' in df.columns and 'is_weekend' in df.columns:\n",
    "        df['temp_x_is_weekend']  = df['temp']  * df['is_weekend']\n",
    "    if 'atemp' in df.columns and 'is_weekend' in df.columns:\n",
    "        df['atemp_x_is_weekend'] = df['atemp'] * df['is_weekend']\n",
    "    return df\n",
    "\n",
    "def fill_lag_roll_nans(df):\n",
    "    lag_roll_cols = [c for c in df.columns if c.startswith('lag_') or c.startswith('roll_')]\n",
    "    # Backward fill then zero for any remaining NaNs\n",
    "    df[lag_roll_cols] = df[lag_roll_cols].bfill().fillna(0)\n",
    "    return df\n",
    "\n",
    "def detect_categoricals(df):\n",
    "    cats = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    for col in df.columns:\n",
    "        if df[col].nunique() < 20 and df[col].dtype in ['int64', 'float64']:\n",
    "            cats.append(col)\n",
    "    return list(set(cats))\n",
    "\n",
    "def one_hot_fit_transform(df_train, df_holdout, categorical_cols, drop_first=True):\n",
    "    \"\"\"Fit categories on train, transform both, and align columns.\"\"\"\n",
    "    train_enc = pd.get_dummies(df_train, columns=categorical_cols, drop_first=drop_first)\n",
    "    hold_enc  = pd.get_dummies(df_holdout, columns=categorical_cols, drop_first=drop_first)\n",
    "    # Align hold-out columns to train columns (add missing with 0, drop extras)\n",
    "    hold_enc = hold_enc.reindex(columns=train_enc.columns, fill_value=0)\n",
    "    return train_enc, hold_enc\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Build features on the full df_ (to avoid leakage for hold-out lags)\n",
    "# -----------------------------\n",
    "df_feat = df_.copy()\n",
    "# Drop columns not used (optional)\n",
    "for col in ['casual', 'registered']:\n",
    "    if col in df_feat.columns:\n",
    "        df_feat = df_feat.drop(columns=[col])\n",
    "\n",
    "df_feat = add_prophet_features(df_feat, time_col=time_col)\n",
    "df_feat = add_lags_and_rolls(df_feat, target_col=target_col)\n",
    "df_feat = add_interactions(df_feat)\n",
    "df_feat = fill_lag_roll_nans(df_feat)\n",
    "\n",
    "# Split features into train/hold-out after feature engineering\n",
    "df_train = df_feat.iloc[:-30, :].copy()\n",
    "df_holdout = df_feat.tail(30).copy()\n",
    "\n",
    "# Remove noisy columns (optional)\n",
    "cols_to_drop = [c for c in df_train.columns if c.startswith('roll_std_')]\n",
    "df_train = df_train.drop(columns=cols_to_drop)\n",
    "df_holdout = df_holdout.drop(columns=[c for c in cols_to_drop if c in df_holdout.columns])\n",
    "\n",
    "# -----------------------------\n",
    "# 5) One-hot encoding (fit on train, align hold-out)\n",
    "# -----------------------------\n",
    "categorical_cols = detect_categoricals(df_train)\n",
    "df_train_enc, df_holdout_enc = one_hot_fit_transform(df_train, df_holdout, categorical_cols, drop_first=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Prepare X/y for train and hold-out\n",
    "# -----------------------------\n",
    "feature_cols = [c for c in df_train_enc.columns if c not in [target_col, time_col]]\n",
    "X_train = df_train_enc[feature_cols].values\n",
    "y_train = df_train_enc[target_col].values\n",
    "\n",
    "X_hold  = df_holdout_enc[feature_cols].values\n",
    "y_hold  = df_holdout_enc[target_col].values\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Hyperparameter tuning on TRAIN ONLY\n",
    "# -----------------------------\n",
    "param_grid = {\n",
    "    'n_estimators': [300, 500, 800, 1000],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', 0.7]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=3,       # quick internal CV on training data\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Tuning hyperparameters on training data...\")\n",
    "search.fit(X_train, y_train)\n",
    "best_rf = search.best_estimator_\n",
    "print(\"Best parameters:\", search.best_params_)\n",
    "\n",
    "# -----------------------------\n",
    "# 8) Fit on training and evaluate on HOLD-OUT (last 30 days)\n",
    "# -----------------------------\n",
    "best_rf.fit(X_train, y_train)\n",
    "pred_hold = best_rf.predict(X_hold)\n",
    "\n",
    "rmse_hold = np.sqrt(mean_squared_error(y_hold, pred_hold))\n",
    "print(f\"Hold-out (last 30 days) RMSE = {rmse_hold:.3f}\")\n",
    "\n",
    "# Optional: attach predictions to the hold-out dataframe for inspection\n",
    "df_eval = df_holdout_raw.copy()\n",
    "df_eval['y_true'] = y_hold\n",
    "df_eval['y_pred'] = pred_hold\n",
    "print(df_eval[['dteday', 'y_true', 'y_pred']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cc29c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added lag feature: 'lag_demand_1h'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 2. Feature engineering\n",
    "\n",
    "# Lag Feature Engineering (CRITICAL FOR TIME SERIES)\n",
    "LAG_PERIOD = 1 \n",
    "df['lag_demand_1h'] = df['cnt'].shift(LAG_PERIOD)\n",
    "\n",
    "# Fill NaN created by shifting (The first few rows will be missing the lag value)\n",
    "# Using 0 for simplicity, or you could drop these rows later if preferred\n",
    "df['lag_demand_1h'] = df['lag_demand_1h'].fillna(0) \n",
    "\n",
    "print(f\"Added lag feature: 'lag_demand_1h'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee2cf96",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# CONFIG\n",
    "\n",
    "FILE_PATH = \"data/dataset/day.csv\" \n",
    "# NOTE: Set the date to split your data (e.g., use all data before '2012-01-01' for training)\n",
    "TEST_SPLIT_DATE = '2012-10-31' \n",
    "\n",
    "param_dist = {\n",
    "    'regressor__n_estimators': [100, 200, 300, 400], # Number of trees\n",
    "    'regressor__max_depth': [10, 20, 30, None],      # Max depth of the trees (None means nodes are expanded until all leaves are pure)\n",
    "    'regressor__min_samples_split': [2, 5, 10],      # Minimum number of samples required to split an internal node\n",
    "    'regressor__min_samples_leaf': [1, 2, 4],        # Minimum number of samples required to be at a leaf node\n",
    "    }\n",
    "\n",
    "N_ITER_SEARCH = 15\n",
    "\n",
    "\n",
    "TARGET_COL = 'cnt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90c9ebf",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014d888c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Identified Feature Types ---\n",
      "Numerical Features: ['temp', 'atemp', 'hum', 'windspeed']\n",
      "Categorical Features: ['season', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit']\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "NUMERICAL_FEATURES = []\n",
    "CATEGORICAL_FEATURES = []\n",
    "\n",
    "for col in FEATURE_COLS:\n",
    "    col_dtype = df[col].dtype\n",
    "    num_unique = df[col].nunique()\n",
    "    \n",
    "    # Rule 1: If dtype is float (e.g., 'temp'), it's numerical.\n",
    "    if np.issubdtype(col_dtype, np.number) and 'float' in str(col_dtype):\n",
    "        NUMERICAL_FEATURES.append(col)\n",
    "    \n",
    "    # Rule 2: If it's a number (int) but has a low number of unique values,\n",
    "    # treat it as categorical for the OneHotEncoder.\n",
    "    elif np.issubdtype(col_dtype, np.number) and num_unique <= 50:\n",
    "        CATEGORICAL_FEATURES.append(col)\n",
    "        \n",
    "    # Rule 3: If it's a high-cardinality integer or a true continuous variable.\n",
    "    elif np.issubdtype(col_dtype, np.number):\n",
    "            NUMERICAL_FEATURES.append(col)\n",
    "    \n",
    "    # Rule 4: If it's an object/string (shouldn't happen much here)\n",
    "    elif col_dtype == 'object':\n",
    "        CATEGORICAL_FEATURES.append(col)\n",
    "        \n",
    "print(\"\\n--- Identified Feature Types ---\")\n",
    "print(f\"Numerical Features: {NUMERICAL_FEATURES}\")\n",
    "print(f\"Categorical Features: {CATEGORICAL_FEATURES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0e2cff",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X = df[FEATURE_COLS]\n",
    "y = df[TARGET_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db36246f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 2a. Create pre-processing pipeline\n",
    "\n",
    "# Define steps for categorical features (One-Hot Encoding)\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # 'passthrough' fixes the error encountered previously and works well \n",
    "        # for numerical features when using Random Forest (no scaling needed)\n",
    "        ('num', 'passthrough', NUMERICAL_FEATURES), \n",
    "        ('cat', categorical_transformer, CATEGORICAL_FEATURES)\n",
    "    ],\n",
    "    remainder='drop' # Drop any columns not explicitly listed in FEATURE_COLS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae283e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Expanding Window Cross-Validation with Tuning ---\n",
      "\n",
      "[Fold 1/5] Training size: 126, Testing size: 121\n",
      "  Tuning Random Forest on current training window (n_iter=10)...\n",
      "  Best Parameters: {'regressor__n_estimators': 100, 'regressor__min_samples_split': 2, 'regressor__min_samples_leaf': 2, 'regressor__max_depth': 10}\n",
      "  Fold Metrics: RMSE=937.16, MAE=789.00\n",
      "\n",
      "[Fold 2/5] Training size: 247, Testing size: 121\n",
      "  Tuning Random Forest on current training window (n_iter=10)...\n",
      "  Best Parameters: {'regressor__n_estimators': 100, 'regressor__min_samples_split': 2, 'regressor__min_samples_leaf': 2, 'regressor__max_depth': 10}\n",
      "  Fold Metrics: RMSE=1125.95, MAE=976.87\n",
      "\n",
      "[Fold 3/5] Training size: 368, Testing size: 121\n",
      "  Tuning Random Forest on current training window (n_iter=10)...\n",
      "  Best Parameters: {'regressor__n_estimators': 100, 'regressor__min_samples_split': 2, 'regressor__min_samples_leaf': 2, 'regressor__max_depth': 10}\n",
      "  Fold Metrics: RMSE=2081.79, MAE=1930.06\n",
      "\n",
      "[Fold 4/5] Training size: 489, Testing size: 121\n",
      "  Tuning Random Forest on current training window (n_iter=10)...\n",
      "  Best Parameters: {'regressor__n_estimators': 100, 'regressor__min_samples_split': 2, 'regressor__min_samples_leaf': 2, 'regressor__max_depth': 10}\n",
      "  Fold Metrics: RMSE=2181.86, MAE=2068.29\n",
      "\n",
      "[Fold 5/5] Training size: 610, Testing size: 121\n",
      "  Tuning Random Forest on current training window (n_iter=10)...\n",
      "  Best Parameters: {'regressor__n_estimators': 100, 'regressor__min_samples_split': 2, 'regressor__min_samples_leaf': 4, 'regressor__max_depth': None}\n",
      "  Fold Metrics: RMSE=2024.64, MAE=1867.67\n",
      "\n",
      "--- Cross-Validation Summary ---\n",
      "Average RMSE over 5 folds: 1670.28\n",
      "Average MAE over 5 folds: 1526.38\n",
      "Average MSE over 5 folds: 3067916.71\n",
      "Average r2 over 5 folds: -1.30\n",
      "avg_RMSE 1670.2805998989509 avg_MAE 1526.380138812328 avg_r2 -1.2970223601343427 avg_mse 3067916.714551232 individual_folds [{'RMSE': np.float64(937.1597848475329), 'MAE': 788.9966027154666, 'MSE': 878268.4623354742, 'r2': -1.2340122332466943, 'Best_Params': {'regressor__n_estimators': 100, 'regressor__min_samples_split': 2, 'regressor__min_samples_leaf': 2, 'regressor__max_depth': 10}}, {'RMSE': np.float64(1125.9458917830373), 'MAE': 976.8720860064983, 'MSE': 1267754.1512230993, 'r2': -0.05022581871247578, 'Best_Params': {'regressor__n_estimators': 100, 'regressor__min_samples_split': 2, 'regressor__min_samples_leaf': 2, 'regressor__max_depth': 10}}, {'RMSE': np.float64(2081.7916937264345), 'MAE': 1930.063647209958, 'MSE': 4333856.656068377, 'r2': -0.8159706465331622, 'Best_Params': {'regressor__n_estimators': 100, 'regressor__min_samples_split': 2, 'regressor__min_samples_leaf': 2, 'regressor__max_depth': 10}}, {'RMSE': np.float64(2181.8641977949083), 'MAE': 2068.294043770833, 'MSE': 4760531.377619218, 'r2': -4.325720771018106, 'Best_Params': {'regressor__n_estimators': 100, 'regressor__min_samples_split': 2, 'regressor__min_samples_leaf': 2, 'regressor__max_depth': 10}}, {'RMSE': np.float64(2024.6414313428415), 'MAE': 1867.6743143588842, 'MSE': 4099172.92550999, 'r2': -0.05918233116127625, 'Best_Params': {'regressor__n_estimators': 100, 'regressor__min_samples_split': 2, 'regressor__min_samples_leaf': 4, 'regressor__max_depth': None}}]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "n_iter_search = 10\n",
    "MIN_TEST_SAMPLES = None\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(\n",
    "        n_splits=n_splits, \n",
    "        max_train_size=None, \n",
    "        test_size= MIN_TEST_SAMPLES\n",
    "    )\n",
    "    \n",
    "cv_metrics = []\n",
    "\n",
    "print(\"\\n--- Starting Expanding Window Cross-Validation with Tuning ---\")\n",
    "\n",
    "param_dist = {\n",
    "        'regressor__n_estimators': [100, 200, 300, 400],\n",
    "        'regressor__max_depth': [10, 20, 30, None],\n",
    "        'regressor__min_samples_split': [2, 5, 10],\n",
    "        'regressor__min_samples_leaf': [1, 2, 4],\n",
    "    }\n",
    "\n",
    "# Inner split for tuning (used inside RandomizedSearchCV)\n",
    "inner_cv = TimeSeriesSplit(n_splits=3,\n",
    "                           test_size=MIN_TEST_SAMPLES)\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "     \n",
    "    # Prepare Data for Current Fold\n",
    "    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    print(f\"\\n[Fold {fold + 1}/{n_splits}] Training size: {len(X_train_fold)}, Testing size: {len(X_test_fold)}\")\n",
    "\n",
    "    # Define the Full ML Pipeline\n",
    "    full_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', RandomForestRegressor(random_state=42, n_jobs=-1))\n",
    "    ])\n",
    "    \n",
    "    # Perform Randomized Search on the CURRENT Training Data\n",
    "    random_search = RandomizedSearchCV(\n",
    "        full_pipeline, \n",
    "        param_distributions=param_dist, \n",
    "        n_iter=n_iter_search, \n",
    "        # We use NEGATIVE MSE because RandomizedSearchCV maximizes the scoring function (minimize RMSE/MAE)\n",
    "        scoring='neg_root_mean_squared_error', \n",
    "        cv=inner_cv, \n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    print(f\"  Tuning Random Forest on current training window (n_iter={n_iter_search})...\")\n",
    "    random_search.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Use the Best Model found to predict on the outer test fold\n",
    "    best_model = random_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test_fold)\n",
    "    \n",
    "    # Evaluate Metrics for this Fold\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_fold, y_pred))\n",
    "    mae = mean_absolute_error(y_test_fold, y_pred)\n",
    "    mse_rf = mean_squared_error(y_test_fold, y_pred)\n",
    "    r2_rf = r2_score(y_test_fold, y_pred)\n",
    "    \n",
    "    \n",
    "    cv_metrics.append({'RMSE': rmse,\n",
    "                       'MAE': mae, \n",
    "                       'MSE': mse_rf,\n",
    "                       'r2':r2_rf,\n",
    "                       'Best_Params': random_search.best_params_})\n",
    "    \n",
    "    print(f\"  Best Parameters: {random_search.best_params_}\")\n",
    "    print(f\"  Fold Metrics: RMSE={rmse:.2f}, MAE={mae:.2f}\")\n",
    "\n",
    "# Calculate and Report Averages\n",
    "avg_rmse = np.mean([m['RMSE'] for m in cv_metrics])\n",
    "avg_mae = np.mean([m['MAE'] for m in cv_metrics])\n",
    "avg_mse = np.mean([m['MSE'] for m in cv_metrics])\n",
    "avg_r2 = np.mean([m['r2'] for m in cv_metrics])\n",
    "\n",
    "print(\"\\n--- Cross-Validation Summary ---\")\n",
    "print(f\"Average RMSE over {n_splits} folds: {avg_rmse:.2f}\")\n",
    "print(f\"Average MAE over {n_splits} folds: {avg_mae:.2f}\")\n",
    "print(f\"Average MSE over {n_splits} folds: {avg_mse:.2f}\")\n",
    "print(f\"Average r2 over {n_splits} folds: {avg_r2:.2f}\")\n",
    "\n",
    "print('avg_RMSE', avg_rmse, 'avg_MAE', avg_mae, 'avg_r2', avg_r2, 'avg_mse', avg_mse, 'individual_folds', cv_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eabcc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>r2</th>\n",
       "      <th>Best_Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1556.949522</td>\n",
       "      <td>1480.772912</td>\n",
       "      <td>2.424092e+06</td>\n",
       "      <td>-4.389010</td>\n",
       "      <td>{'regressor__n_estimators': 300, 'regressor__m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1774.552702</td>\n",
       "      <td>1594.677451</td>\n",
       "      <td>3.149037e+06</td>\n",
       "      <td>-2.472972</td>\n",
       "      <td>{'regressor__n_estimators': 400, 'regressor__m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1128.167306</td>\n",
       "      <td>1039.023279</td>\n",
       "      <td>1.272761e+06</td>\n",
       "      <td>-2.379099</td>\n",
       "      <td>{'regressor__n_estimators': 400, 'regressor__m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1089.491947</td>\n",
       "      <td>1013.736033</td>\n",
       "      <td>1.186993e+06</td>\n",
       "      <td>0.586857</td>\n",
       "      <td>{'regressor__n_estimators': 400, 'regressor__m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>855.118378</td>\n",
       "      <td>768.509039</td>\n",
       "      <td>7.312274e+05</td>\n",
       "      <td>0.036933</td>\n",
       "      <td>{'regressor__n_estimators': 400, 'regressor__m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          RMSE          MAE           MSE        r2  \\\n",
       "0  1556.949522  1480.772912  2.424092e+06 -4.389010   \n",
       "1  1774.552702  1594.677451  3.149037e+06 -2.472972   \n",
       "2  1128.167306  1039.023279  1.272761e+06 -2.379099   \n",
       "3  1089.491947  1013.736033  1.186993e+06  0.586857   \n",
       "4   855.118378   768.509039  7.312274e+05  0.036933   \n",
       "\n",
       "                                         Best_Params  \n",
       "0  {'regressor__n_estimators': 300, 'regressor__m...  \n",
       "1  {'regressor__n_estimators': 400, 'regressor__m...  \n",
       "2  {'regressor__n_estimators': 400, 'regressor__m...  \n",
       "3  {'regressor__n_estimators': 400, 'regressor__m...  \n",
       "4  {'regressor__n_estimators': 400, 'regressor__m...  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pd.DataFrame(cv_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4830e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.25"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "855/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7310899",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b19cb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91da21ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d5519f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd919e13",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eccda5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  weathersit      temp     atemp       hum  windspeed\n",
       "0       1           2  0.344167  0.363625  0.805833   0.160446\n",
       "1       1           2  0.363478  0.353739  0.696087   0.248539\n",
       "2       1           1  0.196364  0.189405  0.437273   0.248309\n",
       "3       1           1  0.200000  0.212122  0.590435   0.160296\n",
       "4       1           1  0.226957  0.229270  0.436957   0.186900"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X_train_fold.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d8baa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size: 696 samples\n",
      "X_test size: 7 samples\n",
      "y_train size: 696 samples\n",
      "y_test size: 7 samples\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Assuming these imports are already done\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Assume X_train, X_test, y_train, y_test are already created \n",
    "# from your time-based split or cross-validation fold\n",
    "\n",
    "n_splits = 5\n",
    "INITIAL_TRAIN_SIZE = 7 \n",
    "\n",
    "# 1. Initialize TimeSeriesSplit\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# We define the inner CV's test size (168 samples = 7 days if data is hourly)\n",
    "MIN_TEST_SAMPLES = 168 \n",
    "tscv = TimeSeriesSplit(\n",
    "    n_splits=n_splits, \n",
    "    max_train_size=None, \n",
    "    test_size=INITIAL_TRAIN_SIZE \n",
    ")\n",
    "\n",
    "# 2. Get Indices for the First Fold (Fold 1/5)\n",
    "# We use next() to get the first (train_index, test_index) pair from the generator\n",
    "train_index, test_index = next(tscv.split(X))\n",
    "\n",
    "\n",
    "# 1. Define the Categorical Transformer (One-Hot Encoding)\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# --- 3. Split the Data into Train and Test Sets for the First Fold ---\n",
    "\n",
    "# Create X_train, X_test by slicing the original DataFrame using the indices\n",
    "X_train = X.iloc[train_index]\n",
    "X_test = X.iloc[test_index]\n",
    "\n",
    "# Create y_train, y_test by slicing the original Series using the indices\n",
    "y_train = y.iloc[train_index]\n",
    "y_test = y.iloc[test_index]\n",
    "\n",
    "# Print sizes to confirm the split\n",
    "print(f\"X_train size: {len(X_train)} samples\")\n",
    "print(f\"X_test size: {len(X_test)} samples\")\n",
    "print(f\"y_train size: {len(y_train)} samples\")\n",
    "print(f\"y_test size: {len(y_test)} samples\")\n",
    "\n",
    "# 2. Combine transformers using ColumnTransformer\n",
    "# Note: NUMERICAL_FEATURES and CATEGORICAL_FEATURES must be defined lists of column names\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Numerical features pass straight through\n",
    "        ('num', 'passthrough', NUMERICAL_FEATURES), \n",
    "        # Categorical features go through the defined encoding pipeline\n",
    "        ('cat', categorical_transformer, CATEGORICAL_FEATURES)\n",
    "    ],\n",
    "    remainder='drop' # Drop any columns not explicitly listed (like 'datetime')\n",
    ")\n",
    "\n",
    "# 3. Fit the preprocessor on the training data and transform it\n",
    "# The output will be a NumPy array.\n",
    "X_train_processed = preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a5eaaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.350371</td>\n",
       "      <td>0.580417</td>\n",
       "      <td>0.052871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>0.368333</td>\n",
       "      <td>0.378779</td>\n",
       "      <td>0.568750</td>\n",
       "      <td>0.148021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>0.278333</td>\n",
       "      <td>0.248742</td>\n",
       "      <td>0.404583</td>\n",
       "      <td>0.376871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>0.245833</td>\n",
       "      <td>0.257583</td>\n",
       "      <td>0.468333</td>\n",
       "      <td>0.150500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>0.313333</td>\n",
       "      <td>0.339004</td>\n",
       "      <td>0.535417</td>\n",
       "      <td>0.046650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>696 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3    4    5    6    7    8    9    10\n",
       "0    0.344167  0.363625  0.805833  0.160446  1.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
       "1    0.363478  0.353739  0.696087  0.248539  1.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
       "2    0.196364  0.189405  0.437273  0.248309  1.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "3    0.200000  0.212122  0.590435  0.160296  1.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "4    0.226957  0.229270  0.436957  0.186900  1.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "..        ...       ...       ...       ...  ...  ...  ...  ...  ...  ...  ...\n",
       "691  0.340000  0.350371  0.580417  0.052871  0.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
       "692  0.368333  0.378779  0.568750  0.148021  0.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
       "693  0.278333  0.248742  0.404583  0.376871  0.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
       "694  0.245833  0.257583  0.468333  0.150500  0.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
       "695  0.313333  0.339004  0.535417  0.046650  0.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
       "\n",
       "[696 rows x 11 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "yy = pd.DataFrame(X_train_processed)\n",
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6500a56",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e082eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data transformed into a NumPy array with shape: (696, 11)\n",
      "\n",
      "Total Number of Features after encoding: 7\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (696, 11), indices imply (696, 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[89]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTotal Number of Features after encoding: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(processed_column_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# C. Convert the array back to a DataFrame for inspection\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m X_processed_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train_processed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprocessed_column_names\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# D. Inspect the final DataFrame structure\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- First 5 Rows of X_train_processed (as DataFrame) ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Interviews/task/data-science-task/.venv/lib/python3.11/site-packages/pandas/core/frame.py:831\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    820\u001b[39m         mgr = dict_to_mgr(\n\u001b[32m    821\u001b[39m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[32m    822\u001b[39m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    828\u001b[39m             copy=_copy,\n\u001b[32m    829\u001b[39m         )\n\u001b[32m    830\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m831\u001b[39m         mgr = \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    832\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[32m    841\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Interviews/task/data-science-task/.venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:336\u001b[39m, in \u001b[36mndarray_to_mgr\u001b[39m\u001b[34m(values, index, columns, dtype, copy, typ)\u001b[39m\n\u001b[32m    331\u001b[39m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[32m    332\u001b[39m index, columns = _get_axes(\n\u001b[32m    333\u001b[39m     values.shape[\u001b[32m0\u001b[39m], values.shape[\u001b[32m1\u001b[39m], index=index, columns=columns\n\u001b[32m    334\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typ == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values.dtype.type, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Interviews/task/data-science-task/.venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:420\u001b[39m, in \u001b[36m_check_values_indices_shape_match\u001b[39m\u001b[34m(values, index, columns)\u001b[39m\n\u001b[32m    418\u001b[39m passed = values.shape\n\u001b[32m    419\u001b[39m implied = (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Shape of passed values is (696, 11), indices imply (696, 7)"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def get_processed_feature_names(column_transformer):\n",
    "    \"\"\"\n",
    "    Retrieves the final feature names after all transformations \n",
    "    (passthrough and OneHotEncoding).\n",
    "    \"\"\"\n",
    "    feature_names = []\n",
    "    \n",
    "    # Iterate through the transformers defined in the ColumnTransformer\n",
    "    for name, transformer, features in column_transformer.transformers_:\n",
    "        \n",
    "        # Check if the transformer is 'passthrough' (numerical features)\n",
    "        if transformer == 'passthrough':\n",
    "            feature_names.extend(features)\n",
    "        \n",
    "        # Check if the transformer is the OneHotEncoder pipeline\n",
    "        elif name == 'cat':\n",
    "            # Use get_feature_names_out() from the OneHotEncoder step\n",
    "            onehot_features = transformer.named_steps['onehot'].get_feature_names_out(features)\n",
    "            feature_names.extend(onehot_features)\n",
    "            \n",
    "        # Note: We skip 'remainder' columns since we set remainder='drop'\n",
    "            \n",
    "    return feature_names\n",
    "\n",
    "\n",
    "# --- Assuming X_train and the fitted preprocessor are available ---\n",
    "\n",
    "# A. Transform the X_train data (using fit_transform, which you already did)\n",
    "# NOTE: If your preprocessor is already fitted from a previous step, \n",
    "# you only need to use 'transform(X_train)' here.\n",
    "X_train_processed = preprocessor.fit_transform(X_train) \n",
    "\n",
    "print(f\" Data transformed into a NumPy array with shape: {X_train_processed.shape}\")\n",
    "\n",
    "\n",
    "# B. Get the final, expanded column names\n",
    "processed_column_names = get_processed_feature_names(preprocessor)\n",
    "\n",
    "print(f\"\\nTotal Number of Features after encoding: {len(processed_column_names)}\")\n",
    "\n",
    "\n",
    "# C. Convert the array back to a DataFrame for inspection\n",
    "X_processed_df = pd.DataFrame(\n",
    "    X_train_processed, \n",
    "    columns=processed_column_names\n",
    ")\n",
    "\n",
    "# D. Inspect the final DataFrame structure\n",
    "print(\"\\n--- First 5 Rows of X_train_processed (as DataFrame) ---\")\n",
    "print(X_processed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e7771b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2c2f0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# --- (Assuming load_data, create_datetime_features, create_preprocessing_pipeline, \n",
    "# and the main execution block are defined as per previous steps) ---\n",
    "\n",
    "# --- Corrected Expanding Window Cross-Validation Function ---\n",
    "\n",
    "def run_expanding_window_cv(X, y, preprocessor_template, param_dist, n_splits=5, initial_train_size=None, n_iter_search=10):\n",
    "    \"\"\"\n",
    "    Performs Expanding Window Cross-Validation with Hyperparameter Tuning \n",
    "    using Randomized Search.\n",
    "    \n",
    "    Args:\n",
    "        X, y: Full feature/target data.\n",
    "        preprocessor_template: The unfitted ColumnTransformer template.\n",
    "        param_dist: The hyperparameter distribution for tuning.\n",
    "        ...\n",
    "    \"\"\"\n",
    "    \n",
    "    # Configuration for TimeSeriesSplit\n",
    "    MIN_TEST_SAMPLES = 168 \n",
    "    \n",
    "    tscv = TimeSeriesSplit(\n",
    "        n_splits=n_splits, \n",
    "        max_train_size=None, \n",
    "        test_size=initial_train_size or MIN_TEST_SAMPLES \n",
    "    )\n",
    "    \n",
    "    cv_metrics = []\n",
    "    inner_cv = TimeSeriesSplit(n_splits=3, test_size=MIN_TEST_SAMPLES)\n",
    "    \n",
    "    print(\"\\n--- Starting Expanding Window Cross-Validation with Tuning ---\")\n",
    "    \n",
    "    for fold, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "        \n",
    "        # 1. Split Data for Current Fold\n",
    "        X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        print(f\"\\n[Fold {fold + 1}/{n_splits}] Training size: {len(X_train_fold)}, Testing size: {len(X_test_fold)}\")\n",
    "\n",
    "        # 2. Define the Full ML Pipeline (Preprocessor + Estimator)\n",
    "        # We use the unfitted template here. The RandomizedSearchCV will handle fitting \n",
    "        # the preprocessor on the inner CV folds.\n",
    "        full_pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor_template), # Pass the TEMPLATE here\n",
    "            ('regressor', RandomForestRegressor(random_state=42, n_jobs=-1))\n",
    "        ])\n",
    "        \n",
    "        # 3. Perform Randomized Search on the CURRENT Training Data\n",
    "        random_search = RandomizedSearchCV(\n",
    "            full_pipeline, \n",
    "            param_distributions=param_dist, \n",
    "            n_iter=n_iter_search, \n",
    "            scoring='neg_mean_squared_error',\n",
    "            cv=inner_cv, \n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        print(f\"  Tuning Random Forest on current training window (n_iter={n_iter_search})...\")\n",
    "        \n",
    "        # --- CRITICAL STEP ---\n",
    "        # search.fit() handles:\n",
    "        # a) Splitting X_train_fold using inner_cv.\n",
    "        # b) On each inner split, it fits the preprocessor and the regressor \n",
    "        #    on the inner train set, then evaluates on the inner test set.\n",
    "        random_search.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # 4. Use the Best Model to predict on the outer test fold\n",
    "        best_model = random_search.best_estimator_\n",
    "        \n",
    "        # --- CRITICAL STEP ---\n",
    "        # best_model (a Pipeline) handles:\n",
    "        # a) Transforming X_test_fold using the preprocessor learned during the final\n",
    "        #    best fit on the entire X_train_fold.\n",
    "        # b) Predicting with the regressor.\n",
    "        y_pred = best_model.predict(X_test_fold)\n",
    "        \n",
    "        # 5. Evaluate Metrics for this Fold\n",
    "        rmse = np.sqrt(mean_squared_error(y_test_fold, y_pred))\n",
    "        mae = mean_absolute_error(y_test_fold, y_pred)\n",
    "        \n",
    "        cv_metrics.append({'RMSE': rmse, 'MAE': mae, 'Best_Params': random_search.best_params_})\n",
    "        \n",
    "        print(f\"  Best Parameters: {random_search.best_params_}\")\n",
    "        print(f\"  Fold Metrics: RMSE={rmse:.2f}, MAE={mae:.2f}\")\n",
    "\n",
    "    # ... (Averaging logic remains the same) ...\n",
    "    avg_rmse = np.mean([m['RMSE'] for m in cv_metrics])\n",
    "    avg_mae = np.mean([m['MAE'] for m in cv_metrics])\n",
    "    \n",
    "    print(\"\\n--- Cross-Validation Summary ---\")\n",
    "    print(f\"Average RMSE over {n_splits} folds: {avg_rmse:.2f}\")\n",
    "    print(f\"Average MAE over {n_splits} folds: {avg_mae:.2f}\")\n",
    "    \n",
    "    return {'avg_RMSE': avg_rmse, 'avg_MAE': avg_mae, 'individual_folds': cv_metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265e822e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b7e63e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c10d4fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# --- 1. Data Loading and Preparation ---\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Loads the dataset, ensuring the datetime column is parsed correctly.\"\"\"\n",
    "    print(f\"Loading data from: {file_path}\")\n",
    "    # Assuming 'datetime' is the time column and 'demand' is the target\n",
    "    df = pd.read_csv(file_path, parse_dates=['dteday'])\n",
    "    df = df.sort_values(by='dteday').reset_index(drop=True)\n",
    "    \n",
    "    # Simple check for target variable\n",
    "    if 'cnt' not in df.columns:\n",
    "        raise ValueError(\"Dataset must contain a 'demand' column.\")\n",
    "    \n",
    "    print(f\"Data loaded with {len(df)} rows and {len(df.columns)} columns.\")\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb275c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=731, step=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f8a56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: data/dataset/day.csv\n",
      "Data loaded with 731 rows and 16 columns.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 731 entries, 0 to 730\n",
      "Data columns (total 16 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   instant     731 non-null    int64         \n",
      " 1   dteday      731 non-null    datetime64[ns]\n",
      " 2   season      731 non-null    int64         \n",
      " 3   yr          731 non-null    int64         \n",
      " 4   mnth        731 non-null    int64         \n",
      " 5   holiday     731 non-null    int64         \n",
      " 6   weekday     731 non-null    int64         \n",
      " 7   workingday  731 non-null    int64         \n",
      " 8   weathersit  731 non-null    int64         \n",
      " 9   temp        731 non-null    float64       \n",
      " 10  atemp       731 non-null    float64       \n",
      " 11  hum         731 non-null    float64       \n",
      " 12  windspeed   731 non-null    float64       \n",
      " 13  casual      731 non-null    int64         \n",
      " 14  registered  731 non-null    int64         \n",
      " 15  cnt         731 non-null    int64         \n",
      "dtypes: datetime64[ns](1), float64(4), int64(11)\n",
      "memory usage: 91.5 KB\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5261e8e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def create_preprocessing_pipeline(numerical_cols, categorical_cols):\n",
    "    \"\"\"\n",
    "    Creates a column transformer for applying different transformations \n",
    "    to numerical and categorical features.\n",
    "    \"\"\"\n",
    "    # Define steps for numerical features (e.g., scaling could be added here)\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        # For Random Forest, often no scaling is needed, but we keep the structure.\n",
    "        ('scaler', StandardScaler()) \n",
    "    ])\n",
    "    \n",
    "    # Define steps for categorical features (One-Hot Encoding)\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    # Combine transformers using ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ],\n",
    "        remainder='passthrough' # Keep any other columns if needed\n",
    "    )\n",
    "    \n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e369251",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5185a407",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- 3. Model Training and Evaluation ---\n",
    "\n",
    "def train_and_evaluate_model(X_train, X_test, y_train, y_test, preprocessor):\n",
    "    \"\"\"\n",
    "    Trains the Random Forest model and evaluates it using RMSE and MAE.\n",
    "    \"\"\"\n",
    "    # 1. Define the full ML Pipeline (Preprocessor + Estimator)\n",
    "    model_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', RandomForestRegressor(\n",
    "            n_estimators=100,      # Number of trees in the forest\n",
    "            random_state=42,       # For reproducibility\n",
    "            n_jobs=-1              # Use all available cores\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # 2. Train the model\n",
    "    print(\"\\n--- Training Random Forest Regressor ---\")\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "    print(\"Training complete.\")\n",
    "    \n",
    "    # 3. Predict on the test set\n",
    "    y_pred = model_pipeline.predict(X_test)\n",
    "    \n",
    "    # 4. Evaluate Metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    # --- 4. Cross-Validation Block (New Function) ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444187d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# --- 4. Cross-Validation Block (Updated Function) ---\n",
    "\n",
    "def run_expanding_window_cv(X, y, preprocessor, param_dist, n_splits=5, initial_train_size=None, n_iter_search=10):\n",
    "    \"\"\"\n",
    "    Performs Expanding Window Cross-Validation with Hyperparameter Tuning \n",
    "    using Randomized Search.\n",
    "    \n",
    "    Args:\n",
    "        ... (existing args) ...\n",
    "        param_dist (dict): The hyperparameter distribution for tuning.\n",
    "        n_iter_search (int): Number of parameter settings that are sampled.\n",
    "    \"\"\"\n",
    "    \n",
    "    tscv = TimeSeriesSplit(\n",
    "        n_splits=n_splits, \n",
    "        max_train_size=None, \n",
    "        test_size=initial_train_size\n",
    "    )\n",
    "    \n",
    "    cv_metrics = []\n",
    "    \n",
    "    print(\"\\n--- Starting Expanding Window Cross-Validation with Tuning ---\")\n",
    "    \n",
    "    # Define a smaller, inner TimeSeriesSplit for tuning the current training fold\n",
    "    inner_cv = TimeSeriesSplit(n_splits=3)\n",
    "    \n",
    "    for fold, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "        \n",
    "        # 1. Prepare Data for Current Fold\n",
    "        X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        print(f\"\\n[Fold {fold + 1}/{n_splits}] Training size: {len(X_train_fold)}, Testing size: {len(X_test_fold)}\")\n",
    "\n",
    "        # 2. Define the Full ML Pipeline (Preprocessor + Estimator)\n",
    "        # We need this pipeline inside the tuning step\n",
    "        full_pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', RandomForestRegressor(random_state=42, n_jobs=-1)) # Use base estimator here\n",
    "        ])\n",
    "        \n",
    "        # 3. Perform Randomized Search on the CURRENT Training Data\n",
    "        # We use NEGATIVE MSE because RandomizedSearchCV maximizes the scoring function (neg_mean_squared_error is minimized)\n",
    "        random_search = RandomizedSearchCV(\n",
    "            full_pipeline, \n",
    "            param_distributions=param_dist, \n",
    "            n_iter=n_iter_search, \n",
    "            scoring='neg_mean_squared_error',\n",
    "            cv=inner_cv, # Use the inner TimeSeriesSplit for tuning\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        print(f\"  Tuning Random Forest on current training window (n_iter={n_iter_search})...\")\n",
    "        random_search.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # 4. Use the Best Model found by the search to predict on the outer test fold\n",
    "        best_model = random_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test_fold)\n",
    "        \n",
    "        # 5. Evaluate Metrics for this Fold\n",
    "        rmse = np.sqrt(mean_squared_error(y_test_fold, y_pred))\n",
    "        mae = mean_absolute_error(y_test_fold, y_pred)\n",
    "        \n",
    "        cv_metrics.append({'RMSE': rmse, 'MAE': mae, 'Best_Params': random_search.best_params_})\n",
    "        \n",
    "        print(f\"  Best Parameters: {random_search.best_params_}\")\n",
    "        print(f\"  Fold Metrics: RMSE={rmse:.2f}, MAE={mae:.2f}\")\n",
    "\n",
    "    # 6. Calculate and Report Averages\n",
    "    # ... (same averaging logic as before) ...\n",
    "    avg_rmse = np.mean([m['RMSE'] for m in cv_metrics])\n",
    "    avg_mae = np.mean([m['MAE'] for m in cv_metrics])\n",
    "    \n",
    "    print(\"\\n--- Cross-Validation Summary ---\")\n",
    "    print(f\"Average RMSE over {n_splits} folds: {avg_rmse:.2f}\")\n",
    "    print(f\"Average MAE over {n_splits} folds: {avg_mae:.2f}\")\n",
    "    \n",
    "    return {'avg_RMSE': avg_rmse, 'avg_MAE': avg_mae, 'individual_folds': cv_metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1038c9a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def run_pipeline(file_path, test_split_date, FEATURE_COLS, TARGET_COL):\n",
    "    \"\"\"Main function to run the entire pipeline.\"\"\"\n",
    "    \n",
    "    # 1. Load Data and Engineer Datetime Features\n",
    "    data = load_data(file_path)\n",
    "    \n",
    "    \n",
    "\n",
    "    data_with_features = data.copy()\n",
    "    # Filter down to the columns we actually use\n",
    "    X = data_with_features[FEATURE_COLS]\n",
    "    y = data_with_features[TARGET_COL]\n",
    "    \n",
    "    # 3. Time-based Train-Test Split\n",
    "    # The split should be based on time to simulate real-world prediction\n",
    "    split_date = pd.to_datetime(test_split_date)\n",
    "    \n",
    "    X_train = X[data_with_features['dteday'] < split_date]\n",
    "    X_test = X[data_with_features['dteday'] >= split_date]\n",
    "    y_train = y[data_with_features['dteday'] < split_date]\n",
    "    y_test = y[data_with_features['dteday'] >= split_date]\n",
    "    \n",
    "    print(f\"\\nTraining set size: {len(X_train)} samples\")\n",
    "    print(f\"Testing set size: {len(X_test)} samples\")\n",
    "    \n",
    "    # 4. Define Column Types for Preprocessing\n",
    "    # This is crucial for applying OneHotEncoder correctly\n",
    "    NUMERICAL_FEATURES = []\n",
    "    CATEGORICAL_FEATURES = []\n",
    "    \n",
    "    for col in FEATURE_COLS:\n",
    "        col_dtype = X_train[col].dtype\n",
    "        num_unique = X_train[col].nunique()\n",
    "        \n",
    "        # Rule 1: If dtype is float (e.g., 'temp'), it's numerical.\n",
    "        if np.issubdtype(col_dtype, np.number) and 'float' in str(col_dtype):\n",
    "            NUMERICAL_FEATURES.append(col)\n",
    "        \n",
    "        # Rule 2: If it's a number (int) but has a low number of unique values,\n",
    "        # treat it as categorical for the OneHotEncoder.\n",
    "        elif np.issubdtype(col_dtype, np.number) and num_unique <= 50:\n",
    "            CATEGORICAL_FEATURES.append(col)\n",
    "            \n",
    "        # Rule 3: If it's a high-cardinality integer or a true continuous variable.\n",
    "        elif np.issubdtype(col_dtype, np.number):\n",
    "             NUMERICAL_FEATURES.append(col)\n",
    "        \n",
    "        # Rule 4: If it's an object/string (shouldn't happen much here)\n",
    "        elif col_dtype == 'object':\n",
    "            CATEGORICAL_FEATURES.append(col)\n",
    "            \n",
    "    print(\"\\n--- Identified Feature Types ---\")\n",
    "    print(f\"Numerical Features: {NUMERICAL_FEATURES}\")\n",
    "    print(f\"Categorical Features: {CATEGORICAL_FEATURES}\")\n",
    "    \n",
    "    # 4. Create Preprocessing Pipeline\n",
    "    preprocessor = create_preprocessing_pipeline(NUMERICAL_FEATURES, CATEGORICAL_FEATURES)\n",
    "    \n",
    "    # 5. Run Expanding Window Cross-Validation!\n",
    "    # Using 5 splits (5 separate training/testing rounds)\n",
    "    # Adjust initial_train_size if you want a different starting window (e.g., 6 months of data)\n",
    "    final_metrics = run_expanding_window_cv(\n",
    "        X, y, preprocessor, \n",
    "        n_splits=5, \n",
    "        initial_train_size=180\n",
    "        # Example: Start with 20% of data for the first training set\n",
    "    )\n",
    "    \n",
    "    return final_metrics # Only returns the metrics now\n",
    "    \n",
    "    # # 5. Create Preprocessing Pipeline\n",
    "    # preprocessor = create_preprocessing_pipeline(NUMERICAL_FEATURES, CATEGORICAL_FEATURES)\n",
    "    \n",
    "    # # 6. Train and Evaluate\n",
    "    # model, metrics = train_and_evaluate_model(X_train, X_test, y_train, y_test, preprocessor)\n",
    "    \n",
    "    # return model, metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ef6072",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7c1acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 731 entries, 0 to 730\n",
      "Data columns (total 16 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   instant     731 non-null    int64         \n",
      " 1   dteday      731 non-null    datetime64[ns]\n",
      " 2   season      731 non-null    int64         \n",
      " 3   yr          731 non-null    int64         \n",
      " 4   mnth        731 non-null    int64         \n",
      " 5   holiday     731 non-null    int64         \n",
      " 6   weekday     731 non-null    int64         \n",
      " 7   workingday  731 non-null    int64         \n",
      " 8   weathersit  731 non-null    int64         \n",
      " 9   temp        731 non-null    float64       \n",
      " 10  atemp       731 non-null    float64       \n",
      " 11  hum         731 non-null    float64       \n",
      " 12  windspeed   731 non-null    float64       \n",
      " 13  casual      731 non-null    int64         \n",
      " 14  registered  731 non-null    int64         \n",
      " 15  cnt         731 non-null    int64         \n",
      "dtypes: datetime64[ns](1), float64(4), int64(11)\n",
      "memory usage: 91.5 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>730</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255833</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.350754</td>\n",
       "      <td>364</td>\n",
       "      <td>1432</td>\n",
       "      <td>1796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>731</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.215833</td>\n",
       "      <td>0.223487</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>0.154846</td>\n",
       "      <td>439</td>\n",
       "      <td>2290</td>\n",
       "      <td>2729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     instant     dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "729      730 2012-12-30       1   1    12        0        0           0   \n",
       "730      731 2012-12-31       1   1    12        0        1           1   \n",
       "\n",
       "     weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n",
       "729           1  0.255833  0.231700  0.483333   0.350754     364        1432   \n",
       "730           2  0.215833  0.223487  0.577500   0.154846     439        2290   \n",
       "\n",
       "      cnt  \n",
       "729  1796  \n",
       "730  2729  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6059a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Hyperparameter Grid for Random Forest\n",
    "# Defines the distributions from which parameters will be sampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dea21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: data/dataset/day.csv\n",
      "Data loaded with 731 rows and 16 columns.\n",
      "\n",
      "Training set size: 669 samples\n",
      "Testing set size: 62 samples\n",
      "\n",
      "--- Identified Feature Types ---\n",
      "Numerical Features: ['temp', 'atemp', 'hum', 'windspeed']\n",
      "Categorical Features: ['season', 'yr', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit']\n",
      "\n",
      " An unexpected error occurred: run_expanding_window_cv() missing 1 required positional argument: 'param_dist'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# --- Execution Example ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # NOTE: Replace 'your_bike_sharing_data.csv' with your actual file path!\n",
    "    FILE_PATH = \"data/dataset/day.csv\" \n",
    "    # NOTE: Set the date to split your data (e.g., use all data before '2012-01-01' for training)\n",
    "    TEST_SPLIT_DATE = '2012-10-31' \n",
    "    \n",
    "    param_dist = {\n",
    "        'regressor__n_estimators': [100, 200, 300, 400], # Number of trees\n",
    "        'regressor__max_depth': [10, 20, 30, None],      # Max depth of the trees (None means nodes are expanded until all leaves are pure)\n",
    "        'regressor__min_samples_split': [2, 5, 10],      # Minimum number of samples required to split an internal node\n",
    "        'regressor__min_samples_leaf': [1, 2, 4],        # Minimum number of samples required to be at a leaf node\n",
    "        }\n",
    "    \n",
    "    N_ITER_SEARCH = 15\n",
    "    \n",
    "    FEATURE_COLS = [\n",
    "        # 'dteday',\n",
    "        'season',\n",
    "        'yr',\n",
    "        'mnth',\n",
    "        'holiday',\n",
    "        'weekday',\n",
    "        'workingday',\n",
    "        'weathersit',\n",
    "        'temp',\n",
    "        'atemp',\n",
    "        'hum',\n",
    "        'windspeed',\n",
    "        # 'casual',\n",
    "        # 'registered',\n",
    "        # 'bikes_cnt',\n",
    "        # 'day'\n",
    "        ]\n",
    "    TARGET_COL = 'cnt'\n",
    "\n",
    "    \n",
    "    try:\n",
    "        # final_model, \n",
    "        final_metrics = run_expanding_window_cv(\n",
    "            X, y, preprocessor, \n",
    "            param_dist=param_dist,\n",
    "            n_splits=5, \n",
    "            initial_train_size=int(len(X) * 0.2),\n",
    "            n_iter_search=N_ITER_SEARCH\n",
    "        )\n",
    "        final_metrics = run_pipeline(FILE_PATH, TEST_SPLIT_DATE, FEATURE_COLS, TARGET_COL)\n",
    "        \n",
    "        print(\"\\n Pipeline Execution Complete.\")\n",
    "        print(f\"Final Model Metrics: {final_metrics}\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\n ERROR: File not found at '{FILE_PATH}'. Please update the FILE_PATH.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d64c4a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdata\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'data' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8a33d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science-task",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
