{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48f0ff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Loading the data\n",
    "df_ = pd.read_csv(FILE_PATH, parse_dates=['dteday'])\n",
    "df_ = df_.sort_values(by='dteday').reset_index(drop=True)\n",
    "\n",
    "# split dataset\n",
    "df_last30 = df_.tail(30)\n",
    "df = df_.iloc[:-30, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55857e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_PARAMS = {\n",
    "    'regressor__n_estimators': 800, \n",
    "     'regressor__min_samples_split': 2,\n",
    "     'regressor__min_samples_leaf': 3,\n",
    "     'regressor__max_depth': None\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87e89ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:03:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:03:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Features: ['temp', 'atemp', 'hum', 'windspeed', 'lag_demand_1d', 'lag_demand_7d', 'temp_lag_1d', 'temp_lag_7d', 'atemp_lag_1d', 'atemp_lag_7d', 'hum_lag_1d', 'hum_lag_7d', 'windspeed_lag_1d', 'windspeed_lag_7d', 'temp_x_is_weekend', 'atemp_x_is_weekend', 'trend', 'yearly', 'weekly']\n",
      "Categorical Features: ['season', 'yr', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit', 'is_weekend']\n",
      "\n",
      "--- Starting CV Tuning (Run this once to finalize BEST_PARAMS_FOUND) ---\n",
      "\n",
      "Average MAPE over 5 folds: 54.36%\n",
      "CV tuning finished. Update BEST_PARAMS_FOUND and run again for final test.\n",
      "\n",
      "======================================================================\n",
      "FINAL MODEL TRAINING & TESTING ON UNSEEN DATA (Requires BEST_PARAMS_FOUND)\n",
      "======================================================================\n",
      "Final Test Set Size (After Engineering): 30 rows\n",
      "Fitting final model on full training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/02 20:03:19 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/02 20:03:21 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/12/02 20:03:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Model Performance on Unseen Test Data (Last 30 Days) ---\n",
      "Final Test RMSE: 1332.95\n",
      "Final Test MAE: 1111.75\n",
      "Final Test MAPE: 66.60%\n",
      "Final Test R2 Score: 0.4451\n",
      "\n",
      "Run ID for Final Evaluation: 1e4e058373e94968b845aac7b644fe30\n",
      "\n",
      "Script execution complete. Run 'mlflow ui' to view all results.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import mlflow\n",
    "import json \n",
    "from sklearn.metrics import make_scorer\n",
    "from prophet import Prophet\n",
    "from xgboost import XGBRegressor \n",
    "import os\n",
    "\n",
    "# --- MLFLOW SETUP ---\n",
    "# Set the experiment name for the final run\n",
    "EXPERIMENT_NAME = \"Bike_Sharing_Demand_FINAL_TEST\" \n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# --- CUSTOM METRIC FUNCTIONS ---\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    \"\"\"Calculates the Mean Absolute Percentage Error (MAPE).\"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    epsilon = 1e-8 \n",
    "    percentage_error = np.abs((y_true - y_pred) / np.where(y_true == 0, epsilon, y_true))\n",
    "    return np.mean(percentage_error) * 100\n",
    "\n",
    "def neg_mean_absolute_percentage_error(y_true, y_pred):\n",
    "    \"\"\"Negated MAPE for scikit-learn scoring.\"\"\"\n",
    "    return -1.0 * mean_absolute_percentage_error(y_true, y_pred)\n",
    "\n",
    "mape_scorer = make_scorer(neg_mean_absolute_percentage_error, greater_is_better=True) \n",
    "\n",
    "# --- CONFIG ---\n",
    "FILE_PATH = \"data/dataset/day.csv\"\n",
    "TARGET_COL = 'cnt'\n",
    "MIN_TEST_SAMPLES = None \n",
    "MAX_TRAIN_SAMPLE = None \n",
    "\n",
    "# Set scoring for CV (use MAPE scorer if optimizing for MAPE)\n",
    "SCORING_MARTIX = \"neg_mean_squared_error\" #mape_scorer \n",
    "N_ITER_SEARCH = 15\n",
    "n_splits = 5\n",
    "\n",
    "param_dist = {\n",
    "    'regressor__n_estimators': [200, 500, 800, 1000, 1500],\n",
    "    'regressor__max_depth': [15, 30, 45, 60, None], \n",
    "    'regressor__min_samples_split': [2, 5, 10, 20, 40],\n",
    "    'regressor__min_samples_leaf': [1, 3, 5, 10, 15],       \n",
    "    }\n",
    "\n",
    "# --- PLACEHOLDER FOR BEST PARAMETERS ---\n",
    "BEST_PARAMS_FOUND = {\"regressor__n_estimators\": 800,\n",
    "                     \"regressor__min_samples_split\": 2,\n",
    "                     \"regressor__min_samples_leaf\": 3,\n",
    "                     \"regressor__max_depth\": None }\n",
    "\n",
    "\n",
    "# --- 1. DATA LOADING AND SPLIT ---\n",
    "if not os.path.exists(FILE_PATH):\n",
    "    raise FileNotFoundError(f\"Data file not found at {FILE_PATH}\")\n",
    "\n",
    "df_ = pd.read_csv(FILE_PATH, parse_dates=['dteday'])\n",
    "df_ = df_.sort_values(by='dteday').reset_index(drop=True)\n",
    "\n",
    "# Split dataset: df is the FULL TRAINING SET, df_last30 is the FINAL TEST SET\n",
    "df_last30 = df_.tail(30).copy()  # Final held-out test data\n",
    "df = df_.iloc[:-30, :].copy()    # Data used for CV/Tuning\n",
    "\n",
    "# --- 2. FEATURE ENGINEERING FUNCTION ---\n",
    "\n",
    "# List of columns to be engineered and used in the final model\n",
    "FEATURE_COLS = [\n",
    "    'season', 'yr', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit', \n",
    "    'temp', 'atemp', 'hum', 'windspeed', 'is_weekend', 'lag_demand_1d', \n",
    "    'lag_demand_7d', 'temp_lag_1d', 'temp_lag_7d', 'atemp_lag_1d', \n",
    "    'atemp_lag_7d', 'hum_lag_1d', 'hum_lag_7d', 'windspeed_lag_1d', \n",
    "    'windspeed_lag_7d', 'temp_x_is_weekend', 'atemp_x_is_weekend',\n",
    "    'trend', 'yearly', 'weekly'\n",
    "]\n",
    "\n",
    "def apply_feature_engineering(data_df, prophet_model=None, train_df=None):\n",
    "    \"\"\"Applies all feature engineering steps to a given DataFrame.\"\"\"\n",
    "    df_eng = data_df.copy()\n",
    "\n",
    "    # Time-based and Interaction Features\n",
    "    df_eng['is_weekend'] = np.where(df_eng['weekday'].isin([5, 6]), 1, 0)\n",
    "    df_eng['temp_x_is_weekend'] = df_eng['temp'] * df_eng['is_weekend']\n",
    "    df_eng['atemp_x_is_weekend'] = df_eng['atemp'] * df_eng['is_weekend']\n",
    "\n",
    "    # Lag Features (Handles both training and test data)\n",
    "    if train_df is not None:\n",
    "        # For Test Data: Pull last values from the Training Data\n",
    "        last_values = {col: train_df[col].iloc[-1] for col in ['cnt', 'temp', 'atemp', 'hum', 'windspeed']}\n",
    "        last_values_7d = {col: train_df[col].iloc[-7] if len(train_df) >= 7 else 0 for col in ['cnt', 'temp', 'atemp', 'hum', 'windspeed']}\n",
    "        \n",
    "        # Demand Lags\n",
    "        df_eng['lag_demand_1d'] = df_eng['cnt'].shift(1).fillna(last_values['cnt'])\n",
    "        df_eng['lag_demand_7d'] = df_eng['cnt'].shift(7).fillna(last_values_7d['cnt'])\n",
    "        \n",
    "        # Weather Lags\n",
    "        for col in ['temp', 'atemp', 'hum', 'windspeed']:\n",
    "            df_eng[f'{col}_lag_1d'] = df_eng[col].shift(1).fillna(last_values[col])\n",
    "            df_eng[f'{col}_lag_7d'] = df_eng[col].shift(7).fillna(last_values_7d[col])\n",
    "            \n",
    "    else:\n",
    "        # For Training Data: Fill the first rows with 0 (or drop them)\n",
    "        for lag in ['lag_demand_1d', 'lag_demand_7d']:\n",
    "            df_eng[lag] = df_eng['cnt'].shift(int(lag.split('_')[-1].replace('d', ''))).fillna(0)\n",
    "        \n",
    "        for col in ['temp', 'atemp', 'hum', 'windspeed']:\n",
    "            df_eng[f'{col}_lag_1d'] = df_eng[col].shift(1).fillna(0)\n",
    "            df_eng[f'{col}_lag_7d'] = df_eng[col].shift(7).fillna(0)\n",
    "\n",
    "    # Prophet Components (Requires fitted model)\n",
    "    if prophet_model:\n",
    "        future = df_eng[['dteday']].rename(columns={'dteday': 'ds'})\n",
    "        forecast = prophet_model.predict(future)\n",
    "        prophet_components = forecast[['ds', 'trend', 'yearly', 'weekly']]\n",
    "        df_eng = df_eng.merge(prophet_components, left_on='dteday', right_on='ds', how='left').drop(columns=['ds'])\n",
    "    \n",
    "    return df_eng.dropna(subset=FEATURE_COLS) # Drop rows that still have NaNs (e.g. from large lags)\n",
    "\n",
    "\n",
    "# --- 3. TRAIN PROPHET MODEL ON FULL TRAINING DATA (`df`) ---\n",
    "prophet_df = df[['dteday', 'cnt']].rename(columns={'dteday': 'ds', 'cnt': 'y'})\n",
    "m = Prophet(growth='linear', yearly_seasonality=True, weekly_seasonality=True, daily_seasonality=True)\n",
    "m.fit(prophet_df) \n",
    "\n",
    "# Apply feature engineering to the full training set (`df`)\n",
    "df = apply_feature_engineering(df, prophet_model=m)\n",
    "\n",
    "\n",
    "# --- 4. FEATURE TYPE IDENTIFICATION and PREPROCESSING ---\n",
    "X = df[FEATURE_COLS]\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "NUMERICAL_FEATURES = []\n",
    "CATEGORICAL_FEATURES = []\n",
    "for col in FEATURE_COLS:\n",
    "    col_dtype = df[col].dtype\n",
    "    num_unique = df[col].nunique()\n",
    "    \n",
    "    if np.issubdtype(col_dtype, np.number) and ('float' in str(col_dtype) or num_unique > 50):\n",
    "        NUMERICAL_FEATURES.append(col)\n",
    "    elif np.issubdtype(col_dtype, np.number) and num_unique <= 50:\n",
    "        CATEGORICAL_FEATURES.append(col)\n",
    "        \n",
    "print(f\"Numerical Features: {NUMERICAL_FEATURES}\")\n",
    "print(f\"Categorical Features: {CATEGORICAL_FEATURES}\")\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', NUMERICAL_FEATURES), \n",
    "        ('cat', categorical_transformer, CATEGORICAL_FEATURES)\n",
    "    ],\n",
    "    remainder='drop' \n",
    ")\n",
    "\n",
    "\n",
    "# --- 5. TIME SERIES CROSS-VALIDATION (CV) LOOP ---\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "inner_cv = TimeSeriesSplit(n_splits=3)\n",
    "cv_metrics = []\n",
    "\n",
    "with mlflow.start_run(run_name=\"Hyperparameter_Tuning_CV\"):\n",
    "    mlflow.log_param(\"SCORING_MARTIX\", str(SCORING_MARTIX))   \n",
    "    mlflow.log_param(\"model_type\", \"RandomForestRegressor\")\n",
    "    \n",
    "    print(\"\\n--- Starting CV Tuning (Run this once to finalize BEST_PARAMS_FOUND) ---\")\n",
    "    for fold, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "        \n",
    "        X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        full_pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', RandomForestRegressor(random_state=42, n_jobs=-1))\n",
    "        ])\n",
    "        \n",
    "        random_search = RandomizedSearchCV(\n",
    "            full_pipeline, param_distributions=param_dist, n_iter=N_ITER_SEARCH, \n",
    "            scoring=SCORING_MARTIX, cv=inner_cv, random_state=42, n_jobs=-1, verbose=0\n",
    "        )\n",
    "        \n",
    "        random_search.fit(X_train_fold, y_train_fold)\n",
    "        best_model = random_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test_fold)\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(y_test_fold, y_pred))\n",
    "        mape = mean_absolute_percentage_error(y_test_fold, y_pred)\n",
    "        \n",
    "        # Log minimal metrics in the loop\n",
    "        mlflow.log_metric(f\"fold_{fold+1}_rmse\", rmse)\n",
    "        mlflow.log_metric(f\"fold_{fold+1}_mape\", mape)\n",
    "        cv_metrics.append({'MAPE': mape, 'RMSE': rmse, 'Best_Params': random_search.best_params_})\n",
    "\n",
    "    avg_mape = np.mean([m['MAPE'] for m in cv_metrics])\n",
    "    mlflow.log_metric(\"avg_mape\", avg_mape)\n",
    "    print(f\"\\nAverage MAPE over {n_splits} folds: {avg_mape:.2f}%\")\n",
    "    print(\"CV tuning finished. Update BEST_PARAMS_FOUND and run again for final test.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696b6305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The CV run ends here\n",
    "\n",
    "# --- 6. FINAL MODEL TRAINING AND TESTING ON UNSEEN DATA ---\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL MODEL TRAINING & TESTING ON UNSEEN DATA (Requires BEST_PARAMS_FOUND)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# --- 6.1. Prepare Test Data (`df_last30`) ---\n",
    "df_test = apply_feature_engineering(df_last30, prophet_model=m, train_df=df)\n",
    "X_test_final = df_test[FEATURE_COLS]\n",
    "y_test_final = df_test[TARGET_COL]\n",
    "print(f\"Final Test Set Size (After Engineering): {len(X_test_final)} rows\")\n",
    "\n",
    "# --- 6.2. Retrain and Test ---\n",
    "with mlflow.start_run(run_name=\"Final_Test_Evaluation_on_Held_Out_Set\"):\n",
    "    \n",
    "    # 1. Define the Final ML Pipeline with Best Parameters\n",
    "    final_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', RandomForestRegressor(random_state=42, n_jobs=-1)) \n",
    "    ])\n",
    "\n",
    "    # 2. Set the best parameters found during CV tuning\n",
    "    final_pipeline.set_params(**BEST_PARAMS_FOUND)\n",
    "\n",
    "    # 3. Fit on the ENTIRE training data (X, y)\n",
    "    print(\"Fitting final model on full training set...\")\n",
    "    final_pipeline.fit(X, y)\n",
    "\n",
    "    # 4. Make predictions on the UNSEEN final test set\n",
    "    y_pred_final = final_pipeline.predict(X_test_final)\n",
    "\n",
    "    # 5. Evaluate final performance\n",
    "    rmse_final = np.sqrt(mean_squared_error(y_test_final, y_pred_final))\n",
    "    mae_final = mean_absolute_error(y_test_final, y_pred_final)\n",
    "    r2_final = r2_score(y_test_final, y_pred_final)\n",
    "    mape_final = mean_absolute_percentage_error(y_test_final, y_pred_final)\n",
    "\n",
    "    # 6. Log the Final Results\n",
    "    mlflow.log_params(BEST_PARAMS_FOUND)\n",
    "    mlflow.log_metric(\"final_test_rmse\", rmse_final)\n",
    "    mlflow.log_metric(\"final_test_mae\", mae_final)\n",
    "    mlflow.log_metric(\"final_test_r2\", r2_final)\n",
    "    mlflow.log_metric(\"final_test_mape\", mape_final)\n",
    "    mlflow.sklearn.log_model(final_pipeline, \"final_validated_model\")\n",
    "    \n",
    "    print(\"\\n--- Final Model Performance on Unseen Test Data (Last 30 Days) ---\")\n",
    "    print(f\"Final Test RMSE: {rmse_final:.2f}\")\n",
    "    print(f\"Final Test MAE: {mae_final:.2f}\")\n",
    "    print(f\"Final Test MAPE: {mape_final:.2f}%\")\n",
    "    print(f\"Final Test R2 Score: {r2_final:.4f}\")\n",
    "    print(\"\\nRun ID for Final Evaluation:\", mlflow.active_run().info.run_id)\n",
    "\n",
    "print(\"\\nScript execution complete. Run 'mlflow ui' to view all results.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science-task",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
