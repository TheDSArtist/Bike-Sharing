{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "bb00408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "55f24cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MLFLOW IMPORTS ---\n",
    "import mlflow\n",
    "import json \n",
    "# ----------------------\n",
    "\n",
    "# --- MLFLOW SETUP ---\n",
    "# Set the experiment name (it will create a folder/database in ./mlruns)\n",
    "EXPERIMENT_NAME = \"Bike_Sharing_Demand_TSCV\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "# --------------------\n",
    "\n",
    "FEATURE_COLS = [\n",
    "    # 'dteday',\n",
    "    'season',\n",
    "    'yr',\n",
    "    'mnth',\n",
    "    'holiday',\n",
    "    'weekday',\n",
    "    'workingday',\n",
    "    'weathersit',\n",
    "    'temp',\n",
    "    'atemp',\n",
    "    'hum',\n",
    "    'windspeed',\n",
    "    'hr',\n",
    "    # 'casual',\n",
    "    # 'registered',\n",
    "    # 'bikes_cnt',\n",
    "    # 'day'\n",
    "    ] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "9e2fabb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
       "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
       "4           1  0.24  0.2879  0.75        0.0       0           1    1  "
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"data/dataset/hour.csv\")\n",
    "df1.head()\n",
    "\n",
    "# df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "715007be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded with 17379 rows and 17 columns.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17379 entries, 0 to 17378\n",
      "Data columns (total 17 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   instant     17379 non-null  int64         \n",
      " 1   dteday      17379 non-null  datetime64[ns]\n",
      " 2   season      17379 non-null  int64         \n",
      " 3   yr          17379 non-null  int64         \n",
      " 4   mnth        17379 non-null  int64         \n",
      " 5   hr          17379 non-null  int64         \n",
      " 6   holiday     17379 non-null  int64         \n",
      " 7   weekday     17379 non-null  int64         \n",
      " 8   workingday  17379 non-null  int64         \n",
      " 9   weathersit  17379 non-null  int64         \n",
      " 10  temp        17379 non-null  float64       \n",
      " 11  atemp       17379 non-null  float64       \n",
      " 12  hum         17379 non-null  float64       \n",
      " 13  windspeed   17379 non-null  float64       \n",
      " 14  casual      17379 non-null  int64         \n",
      " 15  registered  17379 non-null  int64         \n",
      " 16  cnt         17379 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(4), int64(12)\n",
      "memory usage: 2.3 MB\n",
      "\n",
      " None\n",
      "Added lag feature: 'lag_demand_1h'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>...</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>dayofweek_sin</th>\n",
       "      <th>dayofweek_cos</th>\n",
       "      <th>lag_24h</th>\n",
       "      <th>lag_1wk</th>\n",
       "      <th>temp_x_hour_sin</th>\n",
       "      <th>temp_x_is_weekend</th>\n",
       "      <th>atemp_x_hour_sin</th>\n",
       "      <th>atemp_x_is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.119057</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.117633</td>\n",
       "      <td>0.4545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.204550</td>\n",
       "      <td>0.4091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.282843</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.289277</td>\n",
       "      <td>0.4091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.346410</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.354291</td>\n",
       "      <td>0.4091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant     dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1 2011-01-01       1   0     1   0        0        6           0   \n",
       "1       24 2011-01-01       1   0     1  23        0        6           0   \n",
       "2       23 2011-01-01       1   0     1  22        0        6           0   \n",
       "3       22 2011-01-01       1   0     1  21        0        6           0   \n",
       "4       21 2011-01-01       1   0     1  20        0        6           0   \n",
       "\n",
       "   weathersit  ...  hour_sin  hour_cos  dayofweek_sin  dayofweek_cos  lag_24h  \\\n",
       "0           1  ...  0.000000  1.000000      -0.781831        0.62349      0.0   \n",
       "1           2  ... -0.258819  0.965926      -0.781831        0.62349      0.0   \n",
       "2           2  ... -0.500000  0.866025      -0.781831        0.62349      0.0   \n",
       "3           2  ... -0.707107  0.707107      -0.781831        0.62349      0.0   \n",
       "4           2  ... -0.866025  0.500000      -0.781831        0.62349      0.0   \n",
       "\n",
       "   lag_1wk  temp_x_hour_sin  temp_x_is_weekend  atemp_x_hour_sin  \\\n",
       "0      0.0         0.000000               0.24          0.000000   \n",
       "1      0.0        -0.119057               0.46         -0.117633   \n",
       "2      0.0        -0.200000               0.40         -0.204550   \n",
       "3      0.0        -0.282843               0.40         -0.289277   \n",
       "4      0.0        -0.346410               0.40         -0.354291   \n",
       "\n",
       "   atemp_x_is_weekend  \n",
       "0              0.2879  \n",
       "1              0.4545  \n",
       "2              0.4091  \n",
       "3              0.4091  \n",
       "4              0.4091  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# CONFIG\n",
    "FILE_PATH = \"data/dataset/hour.csv\"\n",
    "# FILE_PATH = \"data/dataset/day.csv\"\n",
    "# 1. Loading the data\n",
    "df = pd.read_csv(FILE_PATH, parse_dates=['dteday'])\n",
    "df = df.sort_values(by='dteday').reset_index(drop=True)\n",
    "\n",
    "TARGET_COL = 'cnt'\n",
    "\n",
    "MIN_TEST_SAMPLES =  210 #30  day\n",
    "# MIN_TEST_SAMPLES =  168 # hour\n",
    "\n",
    "MAX_TRAIN_SAMPLE = None # 180 # day\n",
    "# MAX_TRAIN_SAMPLE = 90 # hour\n",
    "\n",
    "# SCORING_MARTIX = \"neg_mean_absolute_error\"\n",
    "# SCORING_MARTIX = 'neg_mean_squared_error'\n",
    "SCORING_MARTIX = \"neg_root_mean_squared_error\"\n",
    " \n",
    "# TEST_SPLIT_DATE = '2012-10-31' \n",
    "\n",
    "print(f\"Data loaded with {len(df)} rows and {len(df.columns)} columns.\")\n",
    "print(\"\\n\", df.info())\n",
    "\n",
    "# 2. Feature engineering\n",
    "\n",
    "df['is_weekend'] = np.where(df['weekday'].isin([5, 6]), 1, 0)\n",
    "\n",
    "# Lag Feature Engineering (CRITICAL FOR TIME SERIES)\n",
    "LAG_PERIOD = 1\n",
    "df['lag_demand_1h'] = df['cnt'].shift(LAG_PERIOD)\n",
    "\n",
    "# Fill NaN created by shifting\n",
    "df['lag_demand_1h'] = df['lag_demand_1h'].fillna(0) \n",
    "\n",
    "# IMPORTANT: Add the lag feature to your FEATURE_COLS for training\n",
    "\n",
    "print(\"Added lag feature: 'lag_demand_1h'\")\n",
    "\n",
    "hour_cycle = 24\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['hr'] / hour_cycle)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['hr'] / hour_cycle)\n",
    "\n",
    "# --- Day of Week (7-day cycle) ---\n",
    "# Calculate the cycle period (7 days)\n",
    "day_cycle = 7\n",
    "df['dayofweek_sin'] = np.sin(2 * np.pi * df['weekday'] / day_cycle)\n",
    "df['dayofweek_cos'] = np.cos(2 * np.pi * df['weekday'] / day_cycle)\n",
    "\n",
    "# Assuming the data is sorted by time and the index frequency matches the lag unit (e.g., hourly data for shift(1))\n",
    "\n",
    "# Lagged Demand (Previous Hour)\n",
    "# Shift the target variable ('count') \n",
    "\n",
    "# Lagged Demand (Same Hour Yesterday)\n",
    "# Shift by 24 time steps (24 hours ago)\n",
    "df['lag_24h'] = df[TARGET_COL].shift(24)\n",
    "df['lag_24h'] = df['lag_24h'].fillna(0) \n",
    "\n",
    "# Lagged Demand (Same Hour Last Week)\n",
    "# Shift by 168 time steps (24 hours * 7 days ago)\n",
    "df['lag_1wk'] = df[TARGET_COL].shift(168)\n",
    "df['lag_1wk'] = df['lag_1wk'].fillna(0)\n",
    "\n",
    "# You can apply shift to other features, e.g., weather conditions \n",
    "# df['temp_lag_1h'] = df['temp'].shift(1)\n",
    "\n",
    "# Interaction: Temperature impact during peak usage hours\n",
    "# Assuming 'temp' is a normalized temperature column\n",
    "df['temp_x_hour_sin'] = df['temp'] * df['hour_sin']\n",
    "\n",
    "# Interaction: Demand on weekends vs. workdays\n",
    "df['temp_x_is_weekend'] = df['temp'] * df['is_weekend']\n",
    "\n",
    "df['atemp_x_hour_sin'] = df['atemp'] * df['hour_sin']\n",
    "\n",
    "# Interaction: Demand on weekends vs. workdays\n",
    "df['atemp_x_is_weekend'] = df['atemp'] * df['is_weekend']\n",
    "\n",
    "FEATURE_COLS.extend(['lag_demand_1h', 'atemp_x_is_weekend','atemp_x_hour_sin', 'temp_x_is_weekend', 'temp_x_hour_sin','lag_1wk', 'lag_24h', 'dayofweek_cos', 'dayofweek_sin', 'hour_cos', 'hour_sin',\n",
    "                     'is_weekend']\n",
    "                     ) \n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "ca2d4c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['season',\n",
       " 'yr',\n",
       " 'mnth',\n",
       " 'holiday',\n",
       " 'weekday',\n",
       " 'workingday',\n",
       " 'weathersit',\n",
       " 'temp',\n",
       " 'atemp',\n",
       " 'hum',\n",
       " 'windspeed',\n",
       " 'hr',\n",
       " 'lag_demand_1h',\n",
       " 'atemp_x_is_weekend',\n",
       " 'atemp_x_hour_sin',\n",
       " 'temp_x_is_weekend',\n",
       " 'temp_x_hour_sin',\n",
       " 'lag_1wk',\n",
       " 'lag_24h',\n",
       " 'dayofweek_cos',\n",
       " 'dayofweek_sin',\n",
       " 'hour_cos',\n",
       " 'hour_sin',\n",
       " 'is_weekend']"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURE_COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "aa0e54ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Identified Feature Types ---\n",
      "Numerical Features: ['temp', 'atemp', 'hum', 'windspeed', 'lag_demand_1h', 'atemp_x_is_weekend', 'atemp_x_hour_sin', 'temp_x_is_weekend', 'temp_x_hour_sin', 'lag_1wk', 'lag_24h', 'dayofweek_cos', 'dayofweek_sin', 'hour_cos', 'hour_sin']\n",
      "Categorical Features: ['season', 'yr', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit', 'hr', 'is_weekend']\n",
      "\n",
      "--- Starting Expanding Window Cross-Validation with Tuning ---\n",
      "\n",
      "[Fold 1/5] Training size: 16329, Testing size: 210\n",
      "  Tuning Random Forest on current training window (n_iter=10)...\n",
      "  Best Parameters: {'regressor__n_estimators': 800, 'regressor__min_samples_split': 2, 'regressor__min_samples_leaf': 3, 'regressor__max_depth': None}\n",
      "  Fold Metrics: RMSE=88.08, MAE=55.76\n",
      "\n",
      "[Fold 2/5] Training size: 16539, Testing size: 210\n",
      "  Tuning Random Forest on current training window (n_iter=10)...\n",
      "  Best Parameters: {'regressor__n_estimators': 800, 'regressor__min_samples_split': 2, 'regressor__min_samples_leaf': 3, 'regressor__max_depth': None}\n",
      "  Fold Metrics: RMSE=55.89, MAE=34.80\n",
      "\n",
      "[Fold 3/5] Training size: 16749, Testing size: 210\n",
      "  Tuning Random Forest on current training window (n_iter=10)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[617]\u001b[39m\u001b[32m, line 116\u001b[39m\n\u001b[32m    104\u001b[39m random_search = RandomizedSearchCV(\n\u001b[32m    105\u001b[39m     full_pipeline, \n\u001b[32m    106\u001b[39m     param_distributions=param_dist, \n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m     verbose=\u001b[32m0\u001b[39m\n\u001b[32m    113\u001b[39m )\n\u001b[32m    115\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Tuning Random Forest on current training window (n_iter=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_iter_search\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m \u001b[43mrandom_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_fold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# Use the Best Model found to predict on the outer test fold\u001b[39;00m\n\u001b[32m    119\u001b[39m best_model = random_search.best_estimator_\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Interviews/task/data-science-task/.venv/lib/python3.11/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Interviews/task/data-science-task/.venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Interviews/task/data-science-task/.venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1992\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1990\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1991\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1992\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1993\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1994\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1995\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1996\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Interviews/task/data-science-task/.venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Interviews/task/data-science-task/.venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Interviews/task/data-science-task/.venv/lib/python3.11/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Interviews/task/data-science-task/.venv/lib/python3.11/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Interviews/task/data-science-task/.venv/lib/python3.11/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         time.sleep(\u001b[32m0.01\u001b[39m)\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Mostly this one is used\n",
    "# param_dist = {\n",
    "#     'regressor__n_estimators': [100, 200, 300, 400], \n",
    "#     'regressor__max_depth': [10, 20, 30, None],      \n",
    "#     'regressor__min_samples_split': [2, 5, 10],      \n",
    "#     'regressor__min_samples_leaf': [1, 2, 4],        \n",
    "#     }\n",
    "\n",
    "param_dist = {\n",
    "    'regressor__n_estimators': [200, 500, 800, 1000, 1500],\n",
    "    'regressor__max_depth': [15, 30, 45, 60, None], # Exploring deeper values\n",
    "    'regressor__min_samples_split': [2, 5, 10, 20, 40], # Testing higher regularization\n",
    "    'regressor__min_samples_leaf': [1, 3, 5, 10, 15],  # Testing higher regularization       \n",
    "    }\n",
    "\n",
    "N_ITER_SEARCH = 15\n",
    "\n",
    "\n",
    "NUMERICAL_FEATURES = []\n",
    "CATEGORICAL_FEATURES = []\n",
    "\n",
    "# Feature Type Identification\n",
    "for col in FEATURE_COLS:\n",
    "    col_dtype = df[col].dtype\n",
    "    num_unique = df[col].nunique()\n",
    "    \n",
    "    if np.issubdtype(col_dtype, np.number) and 'float' in str(col_dtype):\n",
    "        NUMERICAL_FEATURES.append(col)\n",
    "    elif np.issubdtype(col_dtype, np.number) and num_unique <= 50:\n",
    "        CATEGORICAL_FEATURES.append(col)\n",
    "    elif np.issubdtype(col_dtype, np.number):\n",
    "            NUMERICAL_FEATURES.append(col)\n",
    "    elif col_dtype == 'object':\n",
    "        CATEGORICAL_FEATURES.append(col)\n",
    "        \n",
    "print(\"\\n--- Identified Feature Types ---\")\n",
    "print(f\"Numerical Features: {NUMERICAL_FEATURES}\")\n",
    "print(f\"Categorical Features: {CATEGORICAL_FEATURES}\")\n",
    "\n",
    "X = df[FEATURE_COLS]\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "# 2a. Create pre-processing pipeline\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', NUMERICAL_FEATURES), \n",
    "        ('cat', categorical_transformer, CATEGORICAL_FEATURES)\n",
    "    ],\n",
    "    remainder='drop' \n",
    ")\n",
    "\n",
    "n_splits = 5\n",
    "n_iter_search = 10\n",
    "\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(\n",
    "        n_splits=n_splits, \n",
    "        max_train_size=MAX_TRAIN_SAMPLE, \n",
    "        test_size= MIN_TEST_SAMPLES\n",
    "    )\n",
    "    \n",
    "cv_metrics = []\n",
    "\n",
    "print(\"\\n--- Starting Expanding Window Cross-Validation with Tuning ---\")\n",
    "\n",
    "# Inner split for tuning (used inside RandomizedSearchCV)\n",
    "inner_cv = TimeSeriesSplit(n_splits=3,\n",
    "                           test_size=MIN_TEST_SAMPLES)\n",
    "\n",
    "# --- START MLFLOW RUN ---\n",
    "# This context manager automatically starts and ends a run\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    # 1. Log the featured columns as a **parameter**\n",
    "    mlflow.log_param(\"featured_columns\", json.dumps(FEATURE_COLS)) \n",
    "    \n",
    "    # Also log other parameters that define the experiment\n",
    "    mlflow.log_param(\"FILE_PATH\", FILE_PATH)\n",
    "    mlflow.log_param(\"n_splits\", n_splits)\n",
    "    mlflow.log_param(\"n_iter_search\", n_iter_search)\n",
    "    mlflow.log_param(\"model_type\", \"RandomForestRegressor\")\n",
    "    mlflow.log_param(\"SCORING_MARTIX\", SCORING_MARTIX)    \n",
    "    \n",
    "    for fold, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "        \n",
    "        # Prepare Data for Current Fold\n",
    "        X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        print(f\"\\n[Fold {fold + 1}/{n_splits}] Training size: {len(X_train_fold)}, Testing size: {len(X_test_fold)}\")\n",
    "\n",
    "        # Define the Full ML Pipeline\n",
    "        full_pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', RandomForestRegressor(random_state=42, n_jobs=-1))\n",
    "        ])\n",
    "        \n",
    "        # Perform Randomized Search on the CURRENT Training Data\n",
    "        random_search = RandomizedSearchCV(\n",
    "            full_pipeline, \n",
    "            param_distributions=param_dist, \n",
    "            n_iter=n_iter_search, \n",
    "            scoring= SCORING_MARTIX, \n",
    "            cv=inner_cv, \n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        print(f\"  Tuning Random Forest on current training window (n_iter={n_iter_search})...\")\n",
    "        random_search.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Use the Best Model found to predict on the outer test fold\n",
    "        best_model = random_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test_fold)\n",
    "        \n",
    "        # Evaluate Metrics for this Fold\n",
    "        rmse = np.sqrt(mean_squared_error(y_test_fold, y_pred))\n",
    "        mae = mean_absolute_error(y_test_fold, y_pred)\n",
    "        mse_rf = mean_squared_error(y_test_fold, y_pred)\n",
    "        r2_rf = r2_score(y_test_fold, y_pred)\n",
    "        \n",
    "        # 2. Log Fold Metrics as **metrics**\n",
    "        mlflow.log_metric(f\"fold_{fold+1}_rmse\", rmse)\n",
    "        mlflow.log_metric(f\"fold_{fold+1}_mae\", mae)\n",
    "        mlflow.log_metric(f\"fold_{fold+1}_r2\", r2_rf)\n",
    "        mlflow.log_metric(f\"fold_{fold+1}_mse\", mse_rf)\n",
    "        \n",
    "        # 3. Log Best Parameters for the Fold as **parameters**\n",
    "        # Note: You may want to simplify this or only log the final best parameters\n",
    "        # For simplicity, we log all best params for the fold as a parameter\n",
    "        fold_params = {f\"fold_{fold+1}_best_params\": json.dumps(random_search.best_params_)}\n",
    "        mlflow.log_params(fold_params) \n",
    "        \n",
    "        cv_metrics.append({'RMSE': rmse,\n",
    "                           'MAE': mae, \n",
    "                           'MSE': mse_rf,\n",
    "                           'r2':r2_rf,\n",
    "                           'Best_Params': random_search.best_params_})\n",
    "        \n",
    "        print(f\"  Best Parameters: {random_search.best_params_}\")\n",
    "        print(f\"  Fold Metrics: RMSE={rmse:.2f}, MAE={mae:.2f}\")\n",
    "\n",
    "    # Calculate and Report Averages\n",
    "    avg_rmse = np.mean([m['RMSE'] for m in cv_metrics])\n",
    "    avg_mae = np.mean([m['MAE'] for m in cv_metrics])\n",
    "    avg_mse = np.mean([m['MSE'] for m in cv_metrics])\n",
    "    avg_r2 = np.mean([m['r2'] for m in cv_metrics])\n",
    "\n",
    "    # 4. Log the final average metrics\n",
    "    mlflow.log_metric(\"avg_rmse\", avg_rmse)\n",
    "    mlflow.log_metric(\"avg_mae\", avg_mae)\n",
    "    mlflow.log_metric(\"avg_mse\", avg_mse)\n",
    "    mlflow.log_metric(\"avg_r2\", avg_r2)\n",
    "\n",
    "    print(\"\\n--- Cross-Validation Summary ---\")\n",
    "    print(f\"Average RMSE over {n_splits} folds: {avg_rmse:.2f}\")\n",
    "    print(f\"Average MAE over {n_splits} folds: {avg_mae:.2f}\")\n",
    "    print(f\"Average MSE over {n_splits} folds: {avg_mse:.2f}\")\n",
    "    print(f\"Average r2 over {n_splits} folds: {avg_r2:.2f}\")\n",
    "\n",
    "    print('avg_RMSE', avg_rmse, 'avg_MAE', avg_mae, 'avg_r2', avg_r2, 'avg_mse', avg_mse, 'individual_folds', cv_metrics)\n",
    "# The run is automatically ended here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "a5621e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "977\n",
      "1\n",
      "(17379, 29)\n"
     ]
    }
   ],
   "source": [
    "print(df['cnt'].max())\n",
    "print(df['cnt'].min())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98947d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3c9bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fad7fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0af731b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b72e0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5cc7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c97843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5231d213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "612ded66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "69e528b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1        0        6           0   \n",
       "1        2  2011-01-02       1   0     1        0        0           0   \n",
       "2        3  2011-01-03       1   0     1        0        1           1   \n",
       "3        4  2011-01-04       1   0     1        0        2           1   \n",
       "4        5  2011-01-05       1   0     1        0        3           1   \n",
       "\n",
       "   weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n",
       "0           2  0.344167  0.363625  0.805833   0.160446     331         654   \n",
       "1           2  0.363478  0.353739  0.696087   0.248539     131         670   \n",
       "2           1  0.196364  0.189405  0.437273   0.248309     120        1229   \n",
       "3           1  0.200000  0.212122  0.590435   0.160296     108        1454   \n",
       "4           1  0.226957  0.229270  0.436957   0.186900      82        1518   \n",
       "\n",
       "    cnt  \n",
       "0   985  \n",
       "1   801  \n",
       "2  1349  \n",
       "3  1562  \n",
       "4  1600  "
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/dataset/day.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "124f5fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 731 entries, 0 to 730\n",
      "Data columns (total 16 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   instant     731 non-null    int64  \n",
      " 1   dteday      731 non-null    object \n",
      " 2   season      731 non-null    int64  \n",
      " 3   yr          731 non-null    int64  \n",
      " 4   mnth        731 non-null    int64  \n",
      " 5   holiday     731 non-null    int64  \n",
      " 6   weekday     731 non-null    int64  \n",
      " 7   workingday  731 non-null    int64  \n",
      " 8   weathersit  731 non-null    int64  \n",
      " 9   temp        731 non-null    float64\n",
      " 10  atemp       731 non-null    float64\n",
      " 11  hum         731 non-null    float64\n",
      " 12  windspeed   731 non-null    float64\n",
      " 13  casual      731 non-null    int64  \n",
      " 14  registered  731 non-null    int64  \n",
      " 15  cnt         731 non-null    int64  \n",
      "dtypes: float64(4), int64(11), object(1)\n",
      "memory usage: 91.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "b9605a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(731, 30)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "      <th>season_2</th>\n",
       "      <th>season_3</th>\n",
       "      <th>season_4</th>\n",
       "      <th>yr_1</th>\n",
       "      <th>holiday_1</th>\n",
       "      <th>...</th>\n",
       "      <th>mnth_11</th>\n",
       "      <th>mnth_12</th>\n",
       "      <th>weekday_1</th>\n",
       "      <th>weekday_2</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>weekday_4</th>\n",
       "      <th>weekday_5</th>\n",
       "      <th>weekday_6</th>\n",
       "      <th>weathersit_2</th>\n",
       "      <th>weathersit_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>985</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>801</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>1349</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>1562</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>1600</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       temp     atemp       hum  windspeed   cnt  season_2  season_3  \\\n",
       "0  0.344167  0.363625  0.805833   0.160446   985     False     False   \n",
       "1  0.363478  0.353739  0.696087   0.248539   801     False     False   \n",
       "2  0.196364  0.189405  0.437273   0.248309  1349     False     False   \n",
       "3  0.200000  0.212122  0.590435   0.160296  1562     False     False   \n",
       "4  0.226957  0.229270  0.436957   0.186900  1600     False     False   \n",
       "\n",
       "   season_4   yr_1  holiday_1  ...  mnth_11  mnth_12  weekday_1  weekday_2  \\\n",
       "0     False  False      False  ...    False    False      False      False   \n",
       "1     False  False      False  ...    False    False      False      False   \n",
       "2     False  False      False  ...    False    False       True      False   \n",
       "3     False  False      False  ...    False    False      False       True   \n",
       "4     False  False      False  ...    False    False      False      False   \n",
       "\n",
       "   weekday_3  weekday_4  weekday_5  weekday_6  weathersit_2  weathersit_3  \n",
       "0      False      False      False       True          True         False  \n",
       "1      False      False      False      False          True         False  \n",
       "2      False      False      False      False         False         False  \n",
       "3      False      False      False      False         False         False  \n",
       "4       True      False      False      False         False         False  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['instant', 'dteday', 'casual', 'registered'])  # Dropping unnecessary columns\n",
    "\n",
    "# Apply One-Hot Encoding to categorical features\n",
    "df_encoded = pd.get_dummies(df, columns=['season', 'yr', 'holiday', 'workingday', 'mnth', 'weekday', 'weathersit'], drop_first=True)\n",
    "\n",
    "print(df_encoded.shape)\n",
    "\n",
    "# Display the first few rows of the encoded dataset\n",
    "df_encoded.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "ca104e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoded.drop(columns=['cnt'])  # Features\n",
    "y = df_encoded['cnt']  # Target variable\n",
    "\n",
    "# Split data (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "d7cc5adf",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Interviews/task/data-science-task/.venv/lib/python3.11/site-packages/pandas/core/indexing.py:1715\u001b[39m, in \u001b[36m_iLocIndexer._get_list_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1714\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1715\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1716\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m   1717\u001b[39m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Interviews/task/data-science-task/.venv/lib/python3.11/site-packages/pandas/core/generic.py:4175\u001b[39m, in \u001b[36mNDFrame._take_with_is_copy\u001b[39m\u001b[34m(self, indices, axis)\u001b[39m\n\u001b[32m   4166\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4167\u001b[39m \u001b[33;03mInternal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[32m   4168\u001b[39m \u001b[33;03mattribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4173\u001b[39m \u001b[33;03mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[32m   4174\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4175\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4176\u001b[39m \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Interviews/task/data-science-task/.venv/lib/python3.11/site-packages/pandas/core/generic.py:4155\u001b[39m, in \u001b[36mNDFrame.take\u001b[39m\u001b[34m(self, indices, axis, **kwargs)\u001b[39m\n\u001b[32m   4151\u001b[39m     indices = np.arange(\n\u001b[32m   4152\u001b[39m         indices.start, indices.stop, indices.step, dtype=np.intp\n\u001b[32m   4153\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m4155\u001b[39m new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4157\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4158\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4159\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4160\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(new_data, axes=new_data.axes).__finalize__(\n\u001b[32m   4161\u001b[39m     \u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mtake\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4162\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Interviews/task/data-science-task/.venv/lib/python3.11/site-packages/pandas/core/internals/managers.py:910\u001b[39m, in \u001b[36mBaseBlockManager.take\u001b[39m\u001b[34m(self, indexer, axis, verify)\u001b[39m\n\u001b[32m    909\u001b[39m n = \u001b[38;5;28mself\u001b[39m.shape[axis]\n\u001b[32m--> \u001b[39m\u001b[32m910\u001b[39m indexer = \u001b[43mmaybe_convert_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    912\u001b[39m new_labels = \u001b[38;5;28mself\u001b[39m.axes[axis].take(indexer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Interviews/task/data-science-task/.venv/lib/python3.11/site-packages/pandas/core/indexers/utils.py:282\u001b[39m, in \u001b[36mmaybe_convert_indices\u001b[39m\u001b[34m(indices, n, verify)\u001b[39m\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mindices are out-of-bounds\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m indices\n",
      "\u001b[31mIndexError\u001b[39m: indices are out-of-bounds",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[611]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m X_train_fold, X_test_fold = \u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m, X.iloc[test_index]\n\u001b[32m      2\u001b[39m y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Interviews/task/data-science-task/.venv/lib/python3.11/site-packages/pandas/core/indexing.py:1192\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1190\u001b[39m maybe_callable = com.apply_if_callable(key, \u001b[38;5;28mself\u001b[39m.obj)\n\u001b[32m   1191\u001b[39m maybe_callable = \u001b[38;5;28mself\u001b[39m._check_deprecated_callable_usage(key, maybe_callable)\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Interviews/task/data-science-task/.venv/lib/python3.11/site-packages/pandas/core/indexing.py:1744\u001b[39m, in \u001b[36m_iLocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# a list of integers\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[32m-> \u001b[39m\u001b[32m1744\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_list_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# a single integer\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1748\u001b[39m     key = item_from_zerodim(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Interviews/task/data-science-task/.venv/lib/python3.11/site-packages/pandas/core/indexing.py:1718\u001b[39m, in \u001b[36m_iLocIndexer._get_list_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1715\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._take_with_is_copy(key, axis=axis)\n\u001b[32m   1716\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m   1717\u001b[39m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1718\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mpositional indexers are out-of-bounds\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science-task",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
